
\SweaveOpts{prefix.string=figures/HSAUR,eps=FALSE}
<<setup, echo = FALSE, results = tex>>=
source("../LaTeXBibTeX/setup.R")
@


\chapter{Error Rates and $P-$Value Based Multiplicity Adjustments}
\label{chap:theo}

The objective of this chapter is to introduce general concepts
related to multiple testing as well as to describe basic
strategies for the construction of multiple test procedures. In
Section~\ref{sec:concepts} we introduce relevant error concepts,
which extend the classical type I and II error rates. In addition,
general concepts are discussed, such as adjusted and unadjusted
$P-$values, single step and stepwise test procedures, etc. In
Section~\ref{sec:mtp} we review different principles of
constructing multiple test procedures, which include
union-intersection tests, intersection-union tests, closed test
procedures and the partitioning principle. We then review some
commonly used multiple testing procedures constructed from the
marginal $P-$values. Methods under investigation include
Bonferroni-type methods and their improvements
(Section~\ref{sec:bon}) as well as modified Bonferroni methods
based on the Simes test (Section~\ref{sec:simes}). Particular
emphasis lies on the description of the assumptions, advantages
and limitations for the investigated methods.


\section{Error Rates and General Concepts}
\label{sec:concepts}

TBD: Brief overview about this section; Type I error, type II
error, directional decisions, weak and strong error control,
adjusted and unadjusted $P-$values, single-step and stepwise test
procedures

\subsection{Error Rates} \label{ssec:error}

\subsubsection{Type I Error Rates}
\label{sssec:type1}

Let $m \geq 1$ denote the number of null hypotheses $H_1, \ldots,
H_m$ to be tested. Each \textit{elementary hypothesis} $H_i, i=1,
\ldots, m$, is assumed to be associated with a particular
experimental question of interest. For example, if $m=4$ dose
levels of a designated drug are compared with a control treatment,
the elementary hypotheses $H_i$ may denote the event that dose
level $i$ is inferior to the control group, $i=1, \ldots, 4$. As a
further example, the number $m$ of hypotheses can be in the
10'000s in a microarray study and indicate that gene $i$ is not
differentially expressed under two comparative conditions.

In any testing situation, three types of errors can be committed.
False-positives (negatives) occur, when a true (false) null
hypothesis is rejected (retained). In the hypothesis testing
environment, these errors are denoted as type I and type II
errors, respectively. Type III errors are related to the correct
rejection of a null hypothesis with a wrong directional decision.
The related notation is summarized in Table~\ref{tab:error}. Let
$M = \{1, \ldots, m\}$ denote the index set associated with the
null hypotheses $H_1, \ldots, H_m$ and let $M_0 \subseteq M$
denote the set of $m_0 = |M_0|$ true hypotheses. The number of
type I errors is denoted by $V$ and the number of rejected
hypotheses is denoted by $R$. Note that $R$ is an observable
random variable, $S$, $T$, $U$, and $V$ are all unobservable
random variables, while $m$ and $m_0$ are fixed numbers, where
$m_0$ is unknown.

\begin{table} [h!]
\caption{Type I and type II errors in multiple hypotheses
testing.} \label{tab:error}
\begin{center}
\begin{tabular}{c|cc|c}
Hypotheses & not rejected & rejected & \\ \hline
true  & $U$ & $V$ & $m_0$ \\
false & $T$ & $S$ & $m-m_0$ \\ \hline
      & $W$ & $R$ & $m$ \\
\end{tabular}
\end{center}
\end{table}

A standard approach in unviariate hypothesis testing $(m = 1)$ is
to choose an appropriate test, which maintains the type I error
rate at a pre-specified level $\alpha$. In multiple hypothesis
testing several generalizations of the type I error rate are
possible and we review some commonly used error rates in the
following. The \textit{per-comparison error rate}
$$
PCER = \frac{E(V)}{m}
$$
is the expected proportion of type I errors among the $m$
decisions. That is, each test is conducted at level $\alpha$, what
amounts to ignoring the multiplicity problem altogether. The
\textit{familywise error rate}
$$
FWER = P(V > 0)
$$
is the probability of committing at least one type I error. This
is the most common error rate in multiple testing practice. It has
been in use for a long time and reduces to the common type I error
rate in univariate testing situations. However, when the number
$m$ of hypotheses is very large (as it is typically the case in
highdimensional screening studies in molecular biology or early
drug discovery), the FWER is too strict for many practical
applications, i.e., the probability of missing differential
effects is too high. A straightforward extension of the FWER is
the \textit{generalized familywise error rate} $gFWER = P(V > k)$
for pre-specified $k$, see Hommel and Hoffmann (1998) and Lehmann
and Romano (2005) for details.

An alternative approach is to relate the number $V$ of false
positives to the total number $R$ of rejections. Let $Q=V/R$ if
$R>0$ and $Q=0$ otherwise. The \textit{false discovery rate}
\begin{eqnarray*}
FDR &=& E(Q) \\
&=& E\left( \left. \frac{V}{R} \right| R > 0 \right) P(R
> 0) + 0 P(R = 0) \\
&=&  E\left( \left. \frac{V}{R} \right| R > 0 \right) P(R > 0)
\end{eqnarray*}
is then the weighted expected proportion of false-positives among
all significant results (Benjamini and Hochberg, 1995). Early
ideas related to the FDR can be found in Seeger (xxx) and Soric
(xxx). The introduction of the FDR has initiated the investigation
of related alternative criteria and many alternative measures
exist. The positive FDR, for example, is defined as $pFDR = E(V/R
| R > 0)$ (Storey, 2002; Storey, Taylor and Siegmund, 2004) and is
closely related to the Empirical Bayes approach of Efron,
Tibshirani, Storey, and Tusher (2001). A different concept is to
control the proportion $V/R$ directly: Korn et al. (2005) and van
der Laan et al. (2005) independently introduced computer-intensive
multiple test procedures to control the proportion of false
positives $PFP = P( V/R > g ), 0 < g < 1$. We refer to the
original articles for more details.

In general,
$$
PCER \leq FDR \leq FWER
$$
for a given multiple test procedure, since $ V/m \leq 1_{\{R>0\}}
\leq 1_{\{V>0\}}. $ Thus, a multiple test procedure which controls
the FWER also controls the FDR and the PCER, but not vice-versa.
In contrast, FWER controlling procedures are more conservative
than FDR controlling procedures, leading to a smaller number of
rejected hypotheses. In any case, it should be kept in mind that
good scientific practice requires the choice of the type I error
control to be made prior to the data analysis.

Add a sentence like "Due to the widespread use of the FWER and
the FDR, we restrict our attention to these two major error
concepts"? Similar convention, that we consider only "strong"
error control and thus in the following only refer to "FWER
control", if not mentioned otherwise?

 Having introduced different measures for type I errors in the
context of multiple testing, we are now able to define a
\textit{multiple test procedure} as any statistical test procedure
....

For any of the error concepts above, the error control is denoted
as \textit{weak}, if the type I error rate is controlled only
under the \textit{complete null hypothesis}
$$
H=\bigcap_{i \in M_0} H_i, \quad M_0=M.
$$
For example, in case of controlling the FWER weakly, it is
required that $P(V>0 | H) < \alpha$. If, for a given multiple test
procedure, the type I error rate is controlled under any partial
configuration $\emptyset \ne I \subseteq M$ of the $m_0 = |I| \leq
m$ true null hypotheses, the error control is denoted as
\textit{strong}. For example, in case of controlling the FWER
strongly it is required that $\max_{I\subseteq M} P\left(V>0 |
\bigcap_{i \in I} H_i \right)$. Since in practice it is unlikely
that all null hypotheses are true, the complete null hypothesis
$H$ is rarely expected to hold and it is important to apply
multiple test procedures guaranteeing a strong error control. Note
that  if $m_0 = 0$, then  $V = 0$  and $FDR = 0$. If $m_0 = m$,
then $FDR = E( 1 | R > 0) P(R > 0) = P(R > 0) = FWER$ and any FDR
controlling multiple test procedure also controls the FWER weakly.

An open question is on the appropriate choice of null hypotheses
being of primary interest, that is, which set of hypotheses should
constitute the family $H_1, \ldots, H_m$. This topic has often
been under dispute and there seems to be no general guidance. Any
solution will necessarily be application specific and at its best
serve as an example for other areas. Westfall and Bretz (2003),
for example, provided some guidance, when and how to adjust for
multiplicity at different stages of drug development.

\subsubsection{Type II Error Rates}
\label{sssec:type1}

A common requirement for any statistical test is to maximize the
power for a given type I error criterion. As with type I error
rates, the concept of power can be generalized in various ways
when moving from single to multiple hypothesis testing. The
\textit{individual power}
$$
\pi^{ind}_i = P(\mbox{reject} H_i), \quad i \in M_1 = M \setminus
M_0,
$$
gives the rejection probability for a false elementary hypothesis
$H_i$. Closely related to the individual power is the concept of
\textit{average power}. This is defined as the average expected
number of correct rejections of all non-zero elementary
hypotheses, that is,
$$
\pi^{ave} = \frac{E(S)}{m_1} = \frac{1}{m_1}\sum_{i \in
M_1}\pi^{ind}_i.
$$
where $m_1 = |M_1|$ denotes the number of false hypotheses.
Alternatively, the disjunctive power
$$
\pi^{dis} = P(S \geq 1)
$$
gives the probability of rejecting at least one false null
hypothesis. An appealing feature of the disjunctive power is that
$\pi^{dis}$ decreases to the specified FWER as the effect sizes
related to the false null hypotheses $H_i, i \in M_1$, get
smaller. In contrast, the conjunctive power
$$
\pi^{con} = P(S = m_1)
$$
gives the probability of rejecting all false null hypotheses. Note
that the last two power concepts have also been referred to as
minimal and maximal (or complete) power, respectively, but since
$\pi^{dis} \geq \pi^{con}$ this terminology often leads to
confusions. When the family of tests consists of pairwise mean
comparisons, these quantities have been called per-pair power,
any-pair power, and all-pairs power (Ramsey, 1978). In the spirit
of the FDR, one could also define power as $E(S=R|R>0)P(R> 0)$. We
refer to xxx for related power concepts. Note again that all the
above probabilities are conditional on which null hypotheses are
true and which are false. It should also be noted that the above
power definitions are readily extended to any subset $M_1^\prime
\subseteq M_1$ of false null hypotheses.

\subsubsection{Directional Errors}
\label{sssec:type1}

A particular problem arises, when the elementary hypotheses $H_1,
\ldots, H_m$ are two-sided. Having rejected $H_i$, one naturally
wishes to make a directional decision on the sign of the effect
being tested. To make this claim, one requires control of both
type I errors and errors in determining the sign of non-null
effects. A \textit{directional error} (also known as type III
error in the literature) is defined as the rejection of a false
null hypotheses, but where the sign of the true effect parameter
is opposite to the one of its sample estimate.

Let $A_1$ denote the event of at least type I error, i.e., $P(A_1)
= FWER$ and let $A_2$ be the event that there is at least one sign
error among the true non-null effects. The interest is then to
control the \textit{combined error rate}
$$
CER = P(A_1 \cup A_2 )
$$
at a pre-specified level. Stepwise testing methods (see
Section~\ref{ssec:concepts} for a definition) are powerful methods
for controlling FWER (Marcus, Peritz and Gabriel, 1976;
Grechanovsky and Hochberg, 1999), but do not necessarily control
CER. Shaffer (1980) gave a counterexample involving shifted Cauchy
distributions; however, she also noted that for independent tests
statistics satisfying certain distributional conditions (which
include the normal but rule out the Cauchy case), CER is
controlled by at least one stepwise method, Holm`s (1979a)
step-down method. Holm (1979b) also noted CER control for
conditionally independent tests including noncentral multivariate
$t$ with identity dispersion matrix. Finner (1999) further
extended the class of stepwise tests that control CER to include
some step-up tests, closed $F$ tests, and modified $S$-method
tests. He also noted that, while specialized procedures
guaranteeing CER control have been developed (for example, Bauer
et al., 1986), they are often less powerful than standard closed
and stepwise tests. Westfall et al. (2000) systematically
investigated CER rates of stepwise testing methods relevant to
ANOVA studies involving correlated comparisons, using both
analytic and simulation-based methods. No cases of excess
directional error were found for typical applications involving
noncentral multivariate $t$ distributions.




\subsection{General Concepts} \label{ssec:concepts}

\subsubsection{Adjusted P-Values}
\label{sssec:type1}

Similar to univariate hypothesis testing, it is desirable to
compute \textit{adjusted P-values} for a given multiple test
procedure, which are directly compared with the pre-specified
significance level $\alpha$. An adjusted P-value $q_i$ is defined
as the smallest significance level for which one still rejects the
elementary hypothesis $H_i, i \in M$, given a particular multiple
test procedure. In case of the FWER,
$$
q_i = \inf\{\alpha \in (0,1) | H_i \mbox{ is rejected at } FWER =
\alpha\},
$$
see Westfall and Young (1993) and Wright (1992). The
\textit{unadjusted P-values} $p_i$ are often denoted as raw
P-values in the literature. Examples for the computation of
adjusted P-values will be given later in this book.

\subsubsection{Simultaneous Confidence Intervals}
\label{sssec:sci}

TBD

\subsubsection{Single Step and Stepwise Procedures}
\label{sssec:step}

Multiple comparisons procedures can roughly be divided into single
step and stepwise procedures. \textit{Single-step procedures }are
characterized by the fact that the rejection or non-rejection of a
null hypothesis does not depend on the decision of any other
hypothesis. A well known example of a single-step procedure is the
Bonferroni method. In contrast, for \textit{stepwise procedures}
the rejection or non-rejection of a null hypothesis may depend on
the decision of other hypotheses. The equally well known
Bonferroni-Holm method is a stepwise extension of the Bonferroni
method using the closure principle Marcus (see
Section~\ref{sec:bon} for the description of these procedures).
Stepwise procedure are further distinguished into step-down and
step-up procedures. Given a (fixed) sequence of hypotheses $H_{1}
\prec \ldots \prec H_{m}$, \textit{step-down procedures} start
testing the first hypothesis $H_{1}$ in the sequence and step down
through the sequence while rejecting the hypotheses. The procedure
stops at the first non-rejection (at $H_{i}$, say), and $H_{1},
\ldots, H_{i-1}$ are rejected. \textit{Step-up procedures} start
testing $H_{m}$ and step up through the sequence while retaining
the hypotheses. The procedure stops at the first rejection (at
$H_{i}$, say), and $H_{1}, \ldots, H_{i}$ are rejected.

Single step procedures are generally less powerful than their
stepwise extensions in the sense that any hypothesis rejected by
the former procedure will also be rejected by the latter, but not
vice versa. This will become clear when introducing the closure
principle in Section~\ref{ssec:ctp}. The power advantage of
stepwise testing procedures, however, comes only at the cost of
increased difficulties in constructing compatible simultaneous
confidence intervals for the parameter of interest, which have a
joint coverage probability of at least $1-\alpha$.


\subsubsection{Free and Restricted Combinations}
\label{sssec:freecomb}

A set of null hypotheses $H_i, i \in M$, is said to satisfy the
\textit{free combination} condition if for any subset $I \subseteq
M$ the simultaneous truth of $H_i, i \in I$ and falsehood of the
remaining hypotheses is a plausible event. Otherwise, the
hypotheses $H_1, \ldots, H_m$ are said to satisfy the
\textit{restricted combination} condition (Holm, 1979). The
motivation for this distinction will become clear later when
deriving short cut procedures for closed tests.

As an example for a hypotheses set satisfying the free combination
condition, consider the comparison of two treatments with a
control treatment (resulting in $m=2$ null hypotheses). Any of the
three events ``none/one/both of the treatments is better than the
control treatment'' is then a plausible configuration and likely
to be true in practice. As an example for a hypotheses set
satisfying the restricted combination condition, consider all
pairwise comparisons of three treatments means $\mu_1, \mu_2,$ and
$\mu_3$ (resulting in $m=3$ null hypotheses). In this example, not
all configurations of null and alternative hypotheses are
logically possible. For example, if $\mu_1 \neq \mu_2$, then
$\mu_1 = \mu_3$ and $\mu_2 = \mu_3$ can not simultaneously be
true, thus restricting the possible configurations of true and
wrong null hypotheses.



\section{Construction Methods for Multiple Test Procedures}
\label{sec:mtp}

TBD: Brief overview; UIT, IUT, CTP, PP, projection methods


\subsection{Union Intersection Test} \label{ssec:uit}

Historically, the union intersection test has been the first
construction method for multiple test procedures (Roy, 1953; Roy
and Bose, 1953). Assume, for example, that several irrigation
systems are compared with a control. It is then natural to claim
the experiment to be successful, if at least one of the
comparative irrigation systems leads to better results than the
control. If $H_i$ denotes the elementary hypothesis of no
difference in effect between irrigation system $i$ and control, we
wish to correctly reject any (but at least one!) false $H_i$.

To formalize this multiple test problem, let a family of null
hypotheses $H_i$ with associated alternative hypotheses $K_i, i
\in M$, be given. We are then interested in testing
$$
H=\bigcap_{i\in M} H_i \quad \mbox{versus} \quad K=\bigcup_{i\in
M} K_i.
$$
If $T_1, \ldots, T_m$ are the individual test statistics
associated with the hypotheses $H_1, \ldots, H_m$, we reject the
\textit{global null hypothesis} $H$ if and only if $\max_{i\in
M}T_i \geq c$, where the constant $c>0$ is chosen such that the
type I error rate is controlled at level $\alpha$, that is,
$P(\max_{i\in M}T_i \geq c | H) = \alpha$.

This constitutes the \textit{union intersection test}, which thus
tests the intersection of the null hypotheses $H_i$ against the
union of the alternative hypotheses $K_i$. As seen from the
definition of the critical value $c$, the union intersection test
is a single step test. Many common multiple test procedures are by
construction union intersection tests, such as the Bonferroni
method, the Dunnett test, Tukey's all-pairwise comparisons, etc.
Simultaneous confidence intervals are readily obtained by
inverting the individual test statistics.


\subsection{Intersection Union Test} \label{ssec:iut}

Consider the following example from the pharmaceutical practice.
International guidelines require that combination therapies have
to show a clinical benefit against all the individual
monotherapies before being considered for release on the market.
In contrast to the situation described in Section~\ref{ssec:uit},
it is thus required that all null hypotheses of no beneficial
effect are rejected in order to claim the clinical trial to be a
success.

Formally, we are given the test problem
\begin{equation}
\label{eq:iut}
H=\bigcup_{i\in M} H_i \quad \mbox{versus} \quad K=\bigcap_{i\in
M} K_i.
\end{equation}
The \textit{intersection union test} then rejects the global null
hypothesis $H$ at overall level $\alpha$, if all elementary
hypothesis $H_i$ are rejected by their local $\alpha$-level tests
(Berger, 1982). If the test statistics $T_i, i\in M$, have all the
same marginal distribution, the intersection union test rejects
$H$ if and only if $\min_{i\in M}T_i \geq c$, where the $c$ is the
$(1-\alpha)$-quantile from that distribution. In this particular
case the intersection union test is also known as
\textit{min-test}, as coined by Laska and Meisner (1989).

Note that if only some of the null hypotheses $H_i$ are rejected,
the global null hypothesis $H$ is retained and no individual
assessments are possible. This property often leads to the
misconception that the intersection union test is conservative in
the sense that the nominal type I error rate is not exhausted and
therefore the test would lack in power. In fact, the intersection
union test fully exploits the type I error and is moreover
uniformly most powerful within a certain class of monotone
$\alpha$-level tests (Laska and Meisner, 1989). Improvements,
which discard the monotonicity condition or restrict the parameter
space, can be found in Sarkar et al. (1995) and Patel (1991),
respectively. Compatible confidence intervals for intersection
union tests involving two hypotheses are given by Strassburger et
al. (2004).


\subsection{Closure Principle} \label{ssec:ctp}

The union intersection test from Section~\ref{ssec:uit} tests the
global intersection null hypothesis $H$ without formally allowing
for the individual assessments of the elementary hypotheses $H_1,
\ldots, H_m$. That is, if $H=\bigcap_{i\in M} H_i $ is rejected by
the union intersection test, we are still left with the question,
which of the elementary hypotheses $H_i$ should be rejected. The
\textit{closure principle} (Marcus et al., 1976) is a general
construction method which leads to stepwise test procedures
(Section~\ref{sssec:step}) and thus allows to draw individual
conclusions about the elementary hypotheses $H_i$.

\vspace{0.5cm}
%
\begin{figure}[h]
\unitlength 0.5cm
\begin{center}
%
\begin{picture}(20,10)
%
\put(7,4){\makebox(0,0){$H_{1}$}}
\put(13,4){\makebox(0,0){$H_{2}$}}
\put(10,4){\makebox(0,0){$H_{12}$}}
%
% x = 7, y = 4, r = 4
\qbezier(3,4)(3,5.6568)(4.1716,6.8284)
\qbezier(4.1716,6.8284)(5.3431,8)(7,8)
\qbezier(7,8)(8.6569,8)(9.8284,6.8284)
\qbezier(9.8284,6.8284)(11,5.6568)(11,4)
%
\qbezier(3,4)(3,2.3431)(4.1716,1.1716)
\qbezier(4.1716,1.1716)(5.3431,0)(7,0)
\qbezier(7,0)(8.6569,0)(9.8284,1.1716)
\qbezier(9.8284,1.1716)(11,2.3431)(11,4)
%
% x = 13, y = 4, r = 4
\qbezier(9,4)(9,5.6568)(10.1716,6.8284)
\qbezier(10.1716,6.8284)(11.3431,8)(13,8)
\qbezier(13,8)(14.6569,8)(15.8284,6.8284)
\qbezier(15.8284,6.8284)(17,5.6568)(17,4)
%
\qbezier(9,4)(9,2.3431)(10.1716,1.1716)
\qbezier(10.1716,1.1716)(11.3431,0)(13,0)
\qbezier(13,0)(14.6569,0)(15.8284,1.1716)
\qbezier(15.8284,1.1716)(17,2.3431)(17,4)
%%%
\put(7,0){\line(-1,1){4}}
\put(8.7888,0.4223){\line(-1,1){5.35}}
\put(9.8284,1.1716){\line(-1,1){5.65}}
\put(10.5777,2.2111){\line(-1,1){5.35}}
\put(11,4){\line(-1,1){4}}
%
\put(13,0){\line(1,1){4}}
\put(11.2112,0.4223){\line(1,1){5.35}}
\put(10.1717,1.1716){\line(1,1){5.65}}
\put(9.4223,2.2111){\line(1,1){5.35}}
\put(9,4){\line(1,1){4}}
%
\end{picture}
%
\caption{Closure principle for two null hypotheses $H_1$ and $H_2$}
\label{fig:ctp2}
\end{center}
\end{figure}
%
%\vspace{1cm}


To motivate the closure principle, consider initially the case of
$m=2$ null hypotheses $H_1$ and $H_2$. For example, when comparing
two treatments with a control treatment, the two hypotheses of
interest could be $H_1 = \{(\mu_0, \mu_1, \mu_2): \mu_1 - \mu_0
\leq 0 \}$ and $H_2 = \{(\mu_0, \mu_1, \mu_2): \mu_2 - \mu_0 \leq
0 \}$, where $\mu_j$ denotes the mean effect for treatment $j=0
\mbox{ (control)}, 1, 2$. When using the Bonferroni inequality
(which is formally introduced in Section~\ref{sec:bon}), each
hypothesis $H_i$ is tested at level $\alpha/2$ in order to control
the FWER at level $\alpha$. This approach can be improved by
considering the Venn-type diagram in Figure~\ref{fig:ctp2}.
Clearly, testing the intersection hypothesis $H_{12} = H_1 \cap
H_2 = \{(\mu_0, \mu_1, \mu_2): \mu_1 - \mu_0 \leq 0 \mbox{ and }
\mu_2 - \mu_0 \leq 0 \}$ requires an adjustment for multiplicity.
But Figure~\ref{fig:ctp2} also suggests that the remaining parts
$H_1 \setminus H_{12}$ and $H_2 \setminus H_{12}$ can be tested
each at full level $\alpha$. This leads to the ``natural'' test
strategy of first testing the intersection hypothesis $H_{12}$
with an appropriate union intersection test, and if this is
significant, continue testing $H_1$ and $H_2$ at full level
$\alpha$. The null hypothesis $H_1$ is then rejected at FWER
$\alpha$ if both $H_1$ and $H_{12}$ are rejected, each at (local)
level $\alpha$. Conversely, $H_2$ is rejected only if both $H_2$
and $H_{12}$ are rejected. This is exactly the test procedure of
the closure principle, which schematically sketched in
Figure~\ref{fig:ctp2a}.

\vspace{0.5cm}
%
\begin{figure}[h]
\unitlength 0.5cm
\begin{center}
%
\begin{picture}(20,3)
\linethickness{1pt} \put(10,3.25){\makebox(0,0){$H_{12}= H_{1}
\cap H_2$}} \put(6,0){\makebox(0,0){$H_{1}$}}
\put(14,0){\makebox(0,0){$H_{2}$}}
\put(10,2.75){\vector(-2,-1){4}} \put(10,2.75){\vector(2,-1){4}}
%
\end{picture}
\caption{Closure principle for two null hypotheses $H_1$ and $H_2$}
\label{fig:ctp2a}
\end{center}
\end{figure}
%
%\vspace{1cm}


Assume now that $m$ null hypotheses $H_i, i=1, \ldots, m$, are to
be tested (for example, the comparison of $m$ treatments with a
control). The closure principle considers all intersection
hypotheses constructed from the initial hypotheses set. A null
hypothesis $H_i$ is rejected at FWER $\alpha$, if all hypotheses
implying $H_i$ are rejected. More formally, the closure principle
is defined as follows:
\begin{enumerate}
    \item Define a set of elementary hypotheses $H_1, \ldots, H_m$ of interest.
    \item Construct all possible $m' \geq m$ intersection hypotheses $H_I = \bigcap_{i \in I} H_i, I \subseteq \{1, \ldots, m\}$.
    \item For each of the $m'$ hypotheses find a suitable local level-$\alpha$ test.
    \item Reject $H_i$ at FWER $\alpha$, if all hypotheses $H_I$ with $i \in I$ are rejected, each at (local) level $\alpha$.
\end{enumerate}
Note that the choice of the tests for the $m'$ hypotheses is free
and that different tests can be used for different hypotheses.
Adjusted p-values $q_i$ for the null hypotheses $H_i$ are computed
as follows. Let $p_I$ denote the p-value for a given intersection
hypothesis $H_I, I \subseteq \{1, \ldots, m\}$. Then the adjusted
p-value for $H_i$ is defined as
\begin{equation}
\label{eq:ctp-adjp}
q_i = \max_{I: i \in I} p_I, \quad i=1, \ldots, m.
\end{equation}


Consider Figure~\ref{fig:ctp3} for an example of the closure
principle with $m=3$ hypotheses. In this situation, four
additional intersection hypotheses have to be considered to obtain
a closed hypotheses set with $m'=7$. Now, $H_1$ (say) is rejected,
if $H_{123}, H_{12}, H_{13}$ and $H_{1}$ are all rejected at level
$\alpha$, where $H_{ij}=H_i \cap H_j, 1\leq i,j \leq 3$ and
$H_{123}=H_1 \cap H_2 \cap H_3$ is the global intersection
hypothesis.

\vspace{0.5cm}
%
\begin{figure}[h]
\unitlength 0.5cm
\begin{center}
%
\begin{picture}(20,8)
\linethickness{1pt} \put(4,0){\makebox(0,0){$H_{1}$}}
\put(10,0){\makebox(0,0){$H_{2}$}}
\put(16,0){\makebox(0,0){$H_{3}$}}
\put(4,4){\makebox(0,0){$H_{12}$}}
\put(10,4){\makebox(0,0){$H_{13}$}}
\put(16,4){\makebox(0,0){$H_{23}$}}
\put(10,8){\makebox(0,0){$H_{123}$}}
%
\linethickness{0.5pt} \put(4,3.25){\vector(0,-1){2.5}}
\put(4,3.25){\vector(2,-1){5.5}} \put(16,3.25){\vector(0,-1){2.5}}
\put(16,3.25){\vector(-2,-1){5.5}} \put(4,6){\line(1,0){12}}
\put(10,7){\line(0,-1){1}} \put(4,6){\vector(0,-1){1}}
\put(10,6){\vector(0,-1){1}} \put(16,6){\vector(0,-1){1}}
%
\qbezier(4,0.75)(4,2)(7,2) \qbezier(7,2)(10,2)(10,3.25)
%\qbezier(10,0.75)(10,2)(13,2) \qbezier(13,2)(16,2)(16,3.25)
%\qbezier(4,3.25)(4,2)(7,2) \qbezier(7,2)(10,2)(10,0.75)
\qbezier(10,3.25)(10,2)(13,2) \qbezier(13,2)(16,2)(16,0.75)
%
\end{picture}
\caption{Closure principle for three null hypotheses $H_1, H_2,$ and $H_3$}
\label{fig:ctp3}
\end{center}
\end{figure}

The closure principle is a flexible construction method which can
be tailored to a variety of applications. Many common multiple
test procedures are in fact closed test procedures, such as the
step-down procedures of Holm (1979) and Shaffer (198X),
\textit{fixed sequence tests} (Maurer et al., 1995; Westfall and
Krishen, 2001), \textit{fallback procedures} (Wiens, 2003; Wiens
and Dmitrienko, 2005) and \textit{gatekeeping procedures} (Bauer
et al., 1998; Dmitrienko et al., 2003; Chen et al., 2005).

Note that for the closure principle the number $m'$ of operations
is in general of order $2^m$, where $m$ is the number of
hypotheses of interest. It is often useful to find short-cut
procedures that can reduce the number of operations to the order
of $m^2$ or, as the best, of $m$ (Grechanovsky and Hochberg,
1999). The aim of a short-cut procedure is to find decisions for
the elementary (individual) hypotheses, but not necessarily for
the entire closure test. By construction, the decisions resulting
from a short-cut procedure coincide with those of the closure
test. Short-cut procedures thus reduce the computational demand
(which can be substantial for large numbers m of hypotheses when
using the closure test) and allow an easier conduct and
interpretation of the closure test. We refer to Romano and Wolf
(2005) and Hommel et al. (2007), Brannath and Bretz (2008) for
further details.


\subsection{Partitioning Principle} \label{ssec:pp}

The \textit{partitioning principle} was recently introduced by Finner and
Strassburger (2002). By construction, it can lead to more powerful
test procedures than those based on the closure principle. In
addition, simultaneous confidence intervals for the parameters of
interest can be derived, which is typically a difficult task for
closed test procedures.

To motivate the partitioning principle, we consider again the
particular problem from Section~\ref{ssec:ctp} of comparing two
treatments with a control. Let $\vt_i = \mu_i - \mu_0, i=1,2$,
denote the parameters of interest. Let further $\Theta = \real^2$
denote the parameter space with $\bmvartheta =(\vt_1,\vt_2) \in
\Theta$. Recall the two hypotheses of interest, $H_i = \{
\bmvartheta \in \real^2: \vt_i \leq 0\}$, $i=1,2$, and let $K_i =
\Theta \setminus H_i$ denote the associated alternative
hypotheses. We consider the following sets (see also
Figure~\ref{fig:pp}): $\Theta_1 = H_1$, $\Theta_2 = H_2 \cap K_1$,
and $\Theta_3 = K_1 \cap K_2$. Since $\Theta_i, i=1, 2, 3$ are
disjoint and $\Theta_1 \cup \Theta_2 \cup \Theta_3 = \Theta$,
these sets constitute a partition of the parameter space $\Theta$.
The true parameter vector $\bmvartheta$ thus lies in one and only
one of the disjoint subsets $\Theta_i$. Applying (local)
$\alpha$-level tests to each of these subsets therefore leads to a
multiple test procedure which controls the familywise error at
level $\alpha$. A confidence interval for $\bmvartheta$ is
obtained by intersecting the complementary regions of those
hypotheses, which have been rejected. In addition, the
partitioning principle leads to test procedures being at least as
powerful as those derived from the closure principle, since the
type I error has to be controlled only over the smaller subspace
$\Theta_2\varsubsetneq H_2$.

Note that the interpretation of $\Theta_1$ is the same as of $H_1$
(``treatment 1 is not better than the control''). However, the
interpretation of $\Theta_2$ (``treatment 2 is not better than the
control, but treatment 1 is'') has changed as compared with that
of $H_2$ (``treatment 2 is not better than the control''). There
are many possibilities on how to partition the parameter space and
the question remains open, which partition to apply in an actual
problem. Figure~\ref{fig:pp} is one example partition of the real
plane with a straight forward interpretation of its elements,
although other partitions may yield more information about the
parameter $\bmvartheta$.

\vspace{0.5cm}
%
\begin{figure}[h]
\unitlength 0.6cm
\begin{center}
%
\begin{picture}(10,10)
%
\linethickness{1pt}

\put(10.5,5){\makebox(0,0){${\vt_1}$}}
\put(5,10.5){\makebox(0,0){${\vt_2}$}}
\put(2,7){\makebox(0,0){${\Theta_1 = H_1}$}}
\put(7.5,2){\makebox(0,0){${\Theta_2 = H_2 \cap K_1}$}}
\put(7.5,7){\makebox(0,0){${\Theta_3 = K_1 \cap K_2}$}}
%
\linethickness{1pt} \put(0,5){\vector(1,0){10}}
\put(5,0){\vector(0,1){10}}
%
\linethickness{0.2pt}
\multiput(5.2,5.2)(0,0.4){13}{\multiput(0,0)(0.4,0){13}{\circle*{0.1}}}
%
\linethickness{0.2pt}
%
\put(   0.00    ,   0.00    ){\line(0,1){   10.00   }}
\put(   0.20    ,   0.00    ){\line(0,1){   10.00   }}
\put(   0.40    ,   0.00    ){\line(0,1){   10.00   }}
\put(   0.60    ,   0.00    ){\line(0,1){   10.00   }}
\put(   0.80    ,   0.00
){\line(0,1){   10.00   }} \put(   1.00    ,   0.00
){\line(0,1){   10.00   }} \put(   1.20    ,   0.00
){\line(0,1){   10.00   }} \put(   1.40    ,   0.00
){\line(0,1){   10.00   }} \put(   1.60    ,   0.00
){\line(0,1){   10.00   }} \put(   1.80    ,   0.00
){\line(0,1){   10.00   }} \put(   2.00    ,   0.00
){\line(0,1){   10.00   }} \put(   2.20    ,   0.00
){\line(0,1){   10.00   }} \put(   2.40    ,   0.00
){\line(0,1){   10.00   }} \put(   2.60    ,   0.00
){\line(0,1){   10.00   }} \put(   2.80    ,   0.00
){\line(0,1){   10.00   }} \put(   3.00    ,   0.00
){\line(0,1){   10.00   }} \put(   3.20    ,   0.00
){\line(0,1){   10.00   }} \put(   3.40    ,   0.00
){\line(0,1){   10.00   }} \put(   3.60    ,   0.00
){\line(0,1){   10.00   }} \put(   3.80    ,   0.00
){\line(0,1){   10.00   }} \put(   4.00    ,   0.00
){\line(0,1){   10.00   }} \put(   4.20    ,   0.00
){\line(0,1){   10.00   }} \put(   4.40    ,   0.00
){\line(0,1){   10.00   }} \put(   4.60    ,   0.00
){\line(0,1){   10.00   }} \put(   4.80    ,   0.00
){\line(0,1){   10.00   }}
%
\put(   5.15    ,   0.00    ){\line(1,0){   4.85    }}
\put(   5.15    ,   0.20    ){\line(1,0){   4.85    }}
\put(   5.15    ,   0.40    ){\line(1,0){   4.85    }}
\put(   5.15    ,   0.60    ){\line(1,0){   4.85    }}
\put(   5.15    ,   0.80    ){\line(1,0){   4.85    }}
\put(   5.15    ,   1.00    ){\line(1,0){   4.85    }}
\put(   5.15    ,   1.20
){\line(1,0){   4.85    }} \put(   5.15    ,   1.40
){\line(1,0){   4.85    }} \put(   5.15    ,   1.60
){\line(1,0){   4.85    }} \put(   5.15    ,   1.80
){\line(1,0){   4.85    }} \put(   5.15    ,   2.00
){\line(1,0){   4.85    }} \put(   5.15    ,   2.20
){\line(1,0){   4.85    }} \put(   5.15    ,   2.40
){\line(1,0){   4.85    }} \put(   5.15    ,   2.60
){\line(1,0){   4.85    }} \put(   5.15    ,   2.80
){\line(1,0){   4.85    }} \put(   5.15    ,   3.00
){\line(1,0){   4.85    }} \put(   5.15    ,   3.20
){\line(1,0){   4.85    }} \put(   5.15    ,   3.40
){\line(1,0){   4.85    }} \put(   5.15    ,   3.60
){\line(1,0){   4.85    }} \put(   5.15    ,   3.80
){\line(1,0){   4.85    }} \put(   5.15    ,   4.00
){\line(1,0){   4.85    }} \put(   5.15    ,   4.20
){\line(1,0){   4.85    }} \put(   5.15    ,   4.40
){\line(1,0){   4.85    }} \put(   5.15    ,   4.60
){\line(1,0){   4.85    }} \put(   5.15    ,   4.80
){\line(1,0){   4.85    }} \put(   5.15    ,   5.00
){\line(1,0){   4.85    }}
%
\end{picture}
%
\caption{Partitioning principle for two null hypotheses $H_1$ and $H_2$}
\label{fig:pp}
\end{center}
\end{figure}



This previous example illustrates the basic partitioning principle
for two hypotheses. In the general case involving $m$ hypotheses
$H_1, \ldots, H_m$, the partitioning principle can be
characterized as follows.
\begin{enumerate}
    \item Choose an appropriate partition $\{\Theta_{\ell}: \ell\in L\}$ of the parameter space $\Theta$ for some index set $L$.
    \item Test each $\Theta_{\ell}$ with a level-$\alpha$ test.
    \item Reject the null hypothesis $H_i$ if all $\Theta_{\ell}$ with $\Theta_{\ell} \cap H_i \neq \emptyset$ are rejected.
    \item The union of all retained $\Theta_{\ell}$ constitute a confidence set for $\bmvartheta$ at level $1-\alpha$.
\end{enumerate}
For extensions of the basic partitioning principle we refer to
Finner and Strassburger (2002). Early ideas related to the
partitioning principle can be found in Stefansson et al. (1988)
and Hayter and Hsu (1992). Applications of the partitioning
principle have been investigated for a number of testing problems,
such as dose response testing (Hsu and Berger, 1999; Bretz et al.,
2003; Hsu et al., 2006), intersection union tests (Strassburger et
al., 2004), equivalence testing (Finner, Giani, and Strassburger,
2007), and simultaneous confidence intervals for step-up and
step-down procedures (Finner and Strassburger, 2007; Strassburger
and Bretz, 2007).

\subsection{Projection Methods} \label{ssec:proj}

TBD

\section{Multiplicity Adjustments Based on the Bonferroni Inequality}
\label{sec:bon}

The \textit{Bonferroni approach} is a single step procedure, which
compares the unadjusted p-values $p_1, \ldots, p_m$ with the
common threshold $\alpha/m$, where $m$ is the number of hypotheses
under investigation. Equivalently, a null hypothesis $H_i, i \in
M$, is rejected, if the adjusted p-value $q_i=\min(mp_i,1) \leq
\alpha$. Note that the minimum is used only to ensure that the
resulting adjusted p-values $q_i$ are not larger than 1. The
strong FWER control follows directly from Bonferroni's inequality
\begin{equation}
\label{eq:bon}
P(V>0) = P\left(\bigcup_{i\in M_0}\{q_i \leq \alpha\} \right) \leq \sum_{i\in M_0}P(q_i \leq \alpha) \leq m_0\alpha/m \leq \alpha,
\end{equation}
where the probability expressions are conditional on
$\bigcap_{i\in M_0}H_i$ and $M_0 \subseteq M$ denotes the set of
$m_0 = |M_0|$ true null hypotheses.

Consider the following numerical example with $m=3$ null
hypotheses being tested at FWER $\alpha=0.025$. Let $p_1=0.01,
p_2=0.015,$ and $p_3=0.005$ denote the unadjusted p-values. Since
$p_3 < \alpha/3 = 0.0083$, but $p_1, p_2 > \alpha/3$, only the
null hypothesis $H_3$ is rejected. Alternatively, the adjusted
p-values $q_1=0.03, q_2=0.045,$ and $q_3=0.015$ can be calculated
and compared to $\alpha=0.025$, leading to the same test
decisions.

The Bonferroni approach is a very general approach, which is valid
for any correlation structure among the test statistics. However,
the Bonferroni approach is conservative in the sense that other
test procedures exist, which reject at least as many hypotheses as
the Bonferroni approach (often, but not always, at the cost of
additional assumptions on the joint distribution of the test
statistics). In the following we describe some of the improvements
or generalizations of the Bonferroni approach.

A uniform improvement was introduced by Holm (1979). The
\textit{Holm procedure} is a step-down procedure, which basically
consists of repeatedly applying Bonferroni's inequality while
testing the hypotheses  in a data-dependent order. Let $p_{(1)}
\leq \ldots \leq H_{(m)}$ denote the ordered unadjusted p-values
with associated hypotheses $H_{(1)}, \ldots, p_{(m)}$. Then,
$H_{(i)}$ is rejected if $p_{(j)} \leq \alpha/(m-j+1), j=1,
\ldots, i$, that is, if all hypotheses $H_{(j)}$ preceding
$H_{(i)}$ are also rejected. Equivalently, adjusted p-values for
the Holm procedure are given by
\begin{equation}
\label{eq:holm}
q_{(i)} = \min\{1,\max[(m-i+1)p_{(i)},q_{(i-1)}]\}.
\end{equation}

This translates to the following test procedure. Start testing the
null hypothesis $H_{(1)}$ related to the smallest p-value
$p_{(1)}$. If $p_{(1)} > \alpha/m$, the procedure stops and no
hypothesis is rejected. Otherwise, $H_{(1)}$ is rejected and the
procedure continues testing $H_{(2)}$ at the smaller significance
level $\alpha/(m-1)$. These steps are repeated until either the
first non-rejection occurs or all null hypotheses $H_{(1)},
\ldots, H_{(m)}$ are rejected. As a numerical example, consider
again the previous example p-values. Since $p_{(1)} =0.005 <
0.0083 = \alpha/3$, $H_{(1)} = H_3$ is rejected for $\alpha =
0.025$. At the second step, $p_{(2)}=0.01 < 0.0125 = \alpha/2$ and
$H_{(2)} = H_1$ is also rejected. At the final step,
$p_{(3)}=0.015 < 0.025 = \alpha$ and $H_{(3)} = H_2$ is also
rejected. Alternatively, the adjusted p-values are calculated as
$q_{(1)} = 0.015, q_{(2)} =0.02$, and $q_{(3)} =0.02$, which are
all smaller than $\alpha=0.025$ and thus lead to the same test
decisions. Note that $q_{(3)} =0.02$ (and not 0.015, as one could
perhaps expect) due to the monotonicity enforcement induced by the
maximum argument in (\ref{eq:holm}).

It becomes clear from this example that the Holm procedure is a
step-down procedure, which by construction rejects all hypotheses
rejected by the Bonferroni approach and possibly more. A different
perspective on the holm procedure is obtained by considering the
closure principle from Section~\ref{ssec:ctp}. For null hypotheses
$H_1, \ldots, H_m$ satisfying the free combination condition
(Section~\ref{sssec:freecomb}) the Holm procedure is a short cut
of the closure principle, when applying the Bonferroni test to
each intersection hypothesis $H_I = \bigcap_{i \in I} H_i, I
\subseteq \{1, \ldots, m\}$ (Holm, 1979, xxx). That is, the Holm
procedure leads to the same decisions for the elementary
hypotheses $H_1, \ldots, H_m$ as a Bonferroni-based closed test
procedure. To see this, consider again the example from
Section~\ref{ssec:ctp} of comparing two treatments with a control.
The related closure principle for the two null hypotheses $H_1$
and $H_2$ is shown in Figure~\ref{fig:ctp2a}. Assume now that the
Bonferroni test is used to test the intersection hypothesis
$H_{12}=H_1 \cap H_2$, that is, $H_{12}$ is rejected if $\min(p_1,
p_2) \leq \alpha/2$. If $H_{12}$ is rejected, then one of the
elementary hypotheses $H_1$ and $H_2$ is immediately rejected as
well and only the remaining hypothesis needs to be tested at level
$\alpha$: If $p_1 < \alpha/2$, then $H_2$ is tested at level
$\alpha$ and vice versa. More generally, if $H_I = \bigcap_{i \in
I} H_i, I \subseteq M$, is rejected, then there exists an index
$i^* \in I$, such that $p_i^* \leq \alpha/|I|$ and all hypotheses
$H_J$ with $J \subseteq I$ are also rejected (since $|J| \leq |I|$
and thus $p_i^* \leq \alpha/|I| \leq \alpha/|J|$).

If the null hypotheses $H_1, \ldots, H_m$ satisfy only the
restricted combination condition, the Holm procedure is still
applicable, but conservative. Consider the all pairwise
comparisons of three treatments means $\mu_1, \mu_2,$ and $\mu_3$
(resulting in $m=3$ null hypotheses $H_{ij}: \mu_i = \mu_j$). The
related closure principle for the three null hypotheses $H_{12},
H_{13},$ and $H_{23}$ is shown in Figure~\ref{fig:ctp3a}, where
$H_{123}: \mu_1 = \mu_2 = \mu_3$ is the only non-trivial
intersection hypothesis. Applying the Bonferroni test leads to the
rejection of $H_{123}$ if $\min(p_1, p_2, p_3) < \alpha/3$. Once
$H_{123}$ has been rejected, one of the elementary hypotheses is
immediately rejected as well and only the two remaining hypotheses
need to be tested at level $\alpha$. Note that for the ordered set
of p-values $(p_{(1)}, p_{(2)}, p_{(3)})$ the Holm procedure would
apply the significance thresholds $(\alpha/3, \alpha/2, \alpha)$,
whereas the thresholds $(\alpha/3, \alpha, \alpha)$ would suffice,
as seen in the example. Shaffer (1986) extended the Holm procedure
to restricted combinations and provided upper bounds on the
significance thresholds for all pairwise comparison problems.
Westfall (1997) extended Shaffer's method to incorporate
correlations between tests, providing more power.

Do we need more explanations for restricted combinations? They
are important for multcomp.

\vspace{0.5cm}
%
\begin{figure}[h]
\unitlength 0.5cm
\begin{center}
%
\begin{picture}(20,5)
\linethickness{1pt}
\put(4,2){\makebox(0,0){$H_{1}$}}
\put(10,2){\makebox(0,0){$H_{2}$}}
\put(16,2){\makebox(0,0){$H_{3}$}}
\put(10,5){\makebox(0,0){$H_{123}$}}
%
\linethickness{0.5pt}
\put(10,4.3){\vector(-4,-1){5.8}}
\put(10,4.3){\vector(0,-1){1.5}}
\put(10,4.3){\vector(4,-1){5.8}}
%
\end{picture}
\caption{Closure principle for three null hypotheses $H_{ij}:
\mu_i = \mu_j, 1 \leq i < j \leq 3$} \label{fig:ctp3a}
\end{center}
\end{figure}


In the following we mention a few more extensions or
generalization of procedures by Bonferroni and Holm. Simultaneous
confidence intervals being compatible with the Bonferroni test are
easily obtained computing the common marginal confidence intervals
at the adjusted significance levels $\alpha/m$. In case of the
Holm procedure, such confidence intervals are more difficult to
construct (Section~\ref{sssec:sci}). We refer to Strassburger and
Bretz (2008), who applied the partitioning principle from
Section~\ref{ssec:pp} to derive compatible simultaneous confidence
intervals for the Holm procedure and other closed Bonferroni based
tests for one-sided multiple comparison problems.

It follows from (\ref{eq:bon}) that the Bonferroni approach
controls the FWER at level $\alpha$ or less, more specifically
$FWER \leq m_0\alpha/m \leq \alpha$. If the number $m_0$ of true
null hypotheses were known, more powerful procedures could be
obtained by applying the Bonferroni approach at level
$m_0\alpha/m$ instead of $\alpha$. Several methods are available
to estimate $m_0$. Five different estimates were compared in Hsueh
et al. (2003). They concluded that the approach proposed by
Benjamini and Hochberg (2000) gives satisfactory empirical
results. The latter considered the slopes of the lines passing the
points $(m+1, 1)$ and $(i, p_{(i)})$, and take the lowest slope
estimator to approximate $m_0$.

If the test statistics were independent, the FWER could be
calculated as
$$
FWER = P(V>0) = 1-P(V=0) = 1-(1-\alpha)^m.
$$
This gives the motivation for the \v{S}id\'{a}k (1967) approach,
which rejects the null hypothesis $H_i$, if $p_i \leq
1-(1-\alpha)^{1/m}$, or, equivalently, if the adjusted p-value
$q_i = 1-(1-p_i)^m \leq \alpha$. The \v{S}id\'{a}k approach also
holds for non-negatively correlated test statistics (Tong???).
Note that the \v{S}id\'{a}k approach is more powerful than the
Bonferroni approach, although the gain in power is marginal in
practical cases of interest. A further modification of the
Bonferroni approach, which has attracted a lot of research
interest, is based on the Simes inequality introduced in
Section~\ref{sec:simes}. Further improvements of the Bonferroni
approach, which incorporate the information deduced from the
correlation structure, are parametric approaches in the
traditional analysis of variance (ANOVA) set-up discussed in
detail in Chapters~\ref{x,x} and resampling approaches reviewed in
Chapter~\ref{x}.

TBD: weighted Bonferroni; Tarone test (mention Bonferroni test for
discrete data?)


\section{Multiplicity Adjustments Based on Simes Inequality}
\label{sec:simes}

Conditions on correlations (Sarkar paper, see his email); upper
bound on type I error (Hommel, 1986); "Hochberg uses the same set
of significance thresholds as Holm, but it is immediately seen to
be more powerful"

Short section, 2-3 pages at maximum. Include the following
Figures:
\begin{itemize}
\item Comparison of rejection regions for Bonferroni/Simes test

\item Fig from Bjoern Holzhauer

\item Power comparisons (Simes, Bonferroni, possibly also Dunnett
and LRT for many-to-one comparisons), from paper with Senn
\end{itemize}
