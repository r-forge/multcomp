@article{Korn+Freidlin:BJ:2006,
    author = {E. L. Korn and B. Freidlin},
    title = {The likelihood as statistical evidence in multiple comparisons in clinical trials: {No} free lunch},
    journal = {Biometrical Journal},
    month = {JUN},
    year = {2006},
    volumne = {48},
    number = {3},
    isitag = {ISI:000238768100002},
    abstract = {The likelihood ratio summarizes the strength of statistical evidence
for one simple pre-determined hypothesis versus another. However, it
does not directly address the multiple comparisons problem. In this
paper we discuss some concerns related to the application of likelihood
ratio methods to several multiple comparisons issues in clinical
trials, in particular, subgroup analysis, multiple variables, interim
monitoring, and data driven choice of hypotheses.},
    keywords = {Bayesian methods; interim monitoring; frequentist methods; subgroup
analysis; subset analysis; likelihood ratio},
    timescited = {0},
    pages = {346--355},
}
 
@article{Hommel+Kropf:BJ:2005,
    author = {G. Hommel and S. Kropf},
    title = {Tests for differentiation in gene expression using a data-driven order or weights for hypotheses},
    journal = {Biometrical Journal},
    month = {AUG},
    year = {2005},
    volumne = {47},
    number = {4},
    isitag = {ISI:000231492300012},
    abstract = {In the analysis of gene expression by microarrays there are usually few
subjects, but high-dimensional data. By means of techniques, such as
the theory of spherical tests or with suitable permutation tests, it is
possible to sort the endpoints or to give weights to them according to
specific criteria determined by the data while controlling the multiple
type I error rate. The procedures developed so far are based on a
sequential analysis of weighted p-values (corresponding to the
endpoints), including the most extreme situation of weighting leading
to a complete order of p-values. When the data for the endpoints have
approximately equal variances, these procedures show good power
properties. In this paper, we consider an alternative procedure, which
is based on completely sorting the endpoints, but smoothed in the sense
that some perturbations in the sequence of the p-values are allowed.
The procedure is relatively easy to perform, but has high power under
the same restrictions as for the weight-based procedures.},
    keywords = {multiple tests; closure test; familywise error rate; data-driven order
for hypotheses; data-driven weights for hypotheses; gene expression},
    timescited = {2},
    pages = {554--562},
}
 
@article{Bhargava+Spurrier:BJ:2004,
    author = {P. Bhargava and J. D. Spurrier},
    title = {Exact confidence bounds for comparing two regression lines with a control regression line on a fixed interval},
    journal = {Biometrical Journal},
    month = {DEC},
    year = {2004},
    volumne = {46},
    number = {6},
    isitag = {ISI:000226083300009},
    abstract = {The problem of finding exact simultaneous confidence bounds for
comparing simple linear regression lines for two treatments with a
simple linear regression line for the control over a fixed interval is
considered. The assumption that errors are iid normal random is
considered. It is assumed that the design matrices for the two
treatments are equal and the design matrix for the control has the same
number of copies of each distinct row of the design matrix for the
treatments. The method is based on a pivotal quantity that can be
expressed as a function of four t variables. The probability point
depends on the size of an angle associated with the interval. We
present probability points for various sample sizes and angles.},
    keywords = {multiple comparison; simultaneous confidence; probability point;
multivariate-t},
    timescited = {1},
    pages = {720--730},
}
 
@article{Hyakutake:BJ:2003,
    author = {H. Hyakutake},
    title = {Multiple comparisons in nonlinear repeated measurements},
    journal = {Biometrical Journal},
    month = {},
    year = {2003},
    volumne = {45},
    number = {6},
    isitag = {ISI:000185397300010},
    abstract = {It is interest to compare functions of parameters in nonlinear models
for repeated measurements. In a pharmacokinetic model, the maximum
value of the model would be a nonlinear function of some unknown
parameters. In this paper, simultaneous confidence intervals of
functions of parameters in a nonlinear model for repeated mesurement
data are considered to compare the populations.},
    keywords = {confidence interval; nonlinear model; pairwise comparison; repeated
measurement},
    timescited = {0},
    pages = {772--780},
}
 
@article{Cheung+Wu+Quek:BJ:2003,
    author = {S. H. Cheung and K. H. Wu and A. L. Quek},
    title = {Pairwise comparisons in each of several groups with heterogenous group variances},
    journal = {Biometrical Journal},
    month = {},
    year = {2003},
    volumne = {45},
    number = {3},
    isitag = {ISI:000182686400005},
    abstract = {Pairwise comparison procedures are frequently applied to analyze
experimental results. In particular, practitioners in the area of
medical researches often encounter situations which require these
statistical techniques to compare various treatments. In this article,
we focus on pairwise comparison procedures in a two-factor design,
where comparisons of one factor are made simultaneously for each level
of another factor. For example, several new drugs to treat a certain
cancer are being compared for both male and female patients. Previous
research efforts were mainly devoted to models with homogeneous
variances. The current paper is to address more common scenario where
group variances are heterogeneous.},
    keywords = {heterogenous group variances; familywise Type I error; multiple
comparisons},
    timescited = {0},
    pages = {325--334},
}
 
@article{Spurrier:BJ:2002,
    author = {J. D. Spurrier},
    title = {Exact multiple comparisons of three or more regression lines: {Pairwise} comparisons and comparisons with a control},
    journal = {Biometrical Journal},
    month = {},
    year = {2002},
    volumne = {44},
    number = {7},
    isitag = {ISI:000179019200002},
    abstract = {The problem of finding exact simultaneous confidence bounds for
differences in regression models for k groups via the
union-intersection method is considered. The error terms are taken to
be iid normal random variables. Under an assumption slightly more
general than having identical design matrices for each of the k groups,
it is shown that an existing probability point for the multivariate
studentized range can be used to find the necessary probability point
for pairwise comparisons of regression models. The resulting methods
can be used with simple or multiple regression. Under a weaker
assumption on the k design matrices that allows more observations to be
taken from the control group than from the k - 1 treatment groups, a
method is developed for computing exact probability points for
comparing the simple linear regression models of the k - I groups to
that of the control. Within a class of designs, the optimal design for
comparisons with a control takes the square root of (k - 1) times as
many observations from the control than from each treatment group. The
simultaneous confidence bounds for all pairwise differences and for
comparisons with a control are much narrower than Spurrier's intervals
for all contrasts of k regression lines.},
    keywords = {confidence bound; multivariate studentized range; simultaneous
confidence; simple linear regression; union-intersection},
    timescited = {2},
    pages = {801--812},
}
 
@article{Wilcox:BJ:2002,
    author = {R. R. Wilcox},
    title = {Multiple comparisons among dependent groups based on a modified one-step {M-estimator}},
    journal = {Biometrical Journal},
    month = {},
    year = {2002},
    volumne = {44},
    number = {4},
    isitag = {ISI:000176420400005},
    abstract = {Currently, among multiple comparison procedures for dependent groups, a
bootstrap-t with a 20% trimmed mean performs relatively well in terms
of both Type I error probabilities and power. However, trimmed means
suffer from two general concerns described in the paper. Robust
M-estimators address these concerns, but now no method has been found
that gives good control over the probability of a Type I error when
sample sizes are small. The paper suggests using instead a modified
one-step M-estimator that retains the advantages of both trimmed means
and robust M-estimators. Yet another concern is that the more
successful methods for trimmed means can be too conservative in terms
of Type I errors. Two methods for performing all pairwise multiple
comparisons are considered. In simulations, both methods avoid a
familywise error (FWE) rate larger than the nominal level. The method
based on comparing measures of location associated with the marginal
distributions can have an actual FWE that is well below the nominal
level when variables are highly correlated. However, the method based
on difference scores performs reasonably well with very small sample
sizes, and it generally performs better than any of the methods studied
in Wilcox (1997b).},
    keywords = {M-estimators; asymmetric trimming; bootstrap; depth},
    timescited = {1},
    pages = {466--477},
}
 
@article{Biesheuvel+Hothorn:BJ:2002,
    author = {E. Biesheuvel and L. A. Hothorn},
    title = {Many-to-one comparisons in stratified designs},
    journal = {Biometrical Journal},
    month = {},
    year = {2002},
    volumne = {44},
    number = {1},
    isitag = {ISI:000173765200007},
    abstract = {CHEUNG and HOLLAND ( 1992) extended Dunnett's procedure for comparing
all active treatments with a control simultaneously within each of r
groups while maintaining the Type I error rate at some designated level
alpha allowing different sample sizes for each of the group-treatment
categories. This paper shows that exact percentage points can be easily
calculated with current available statistical software (SAS). This
procedure is compared to resampling techniques and a Bonferroni
corrected Dunnett-within-group procedure by means of a simulation study.},
    keywords = {comparisons with a control; Stratified Design; Resampling Techniques},
    timescited = {2},
    pages = {101--116},
}
 
@article{Bauer+Hothorn+Westfall:BJ:2001,
    author = {P. Bauer and L. A. Hothorn and P. Westfall},
    title = {Special issue multiple comparison procedures},
    journal = {Biometrical Journal},
    month = {},
    year = {2001},
    volumne = {43},
    number = {5},
    isitag = {ISI:000171069400001},
    abstract = {NA},
    keywords = {NA},
    timescited = {0},
    pages = {531--531},
}
 
@article{Rogers+Hsu:BJ:2001,
    author = {J. A. Rogers and J. C. Hsu},
    title = {Multiple comparisons of biodiversity},
    journal = {Biometrical Journal},
    month = {},
    year = {2001},
    volumne = {43},
    number = {5},
    isitag = {ISI:000171069400009},
    abstract = {A common goal in statistical ecology is to compare several communities
and or time points with respect to taxonomic diversity (usually species
diversity). For this purpose, the current literature recommends the
application of traditional ANOVA techniques to "replicates" of
diversity indices. This approach is not even asymptotically correct
because diversity index estimates have unequal variances, even when
sample sizes are equal and even when the hypothesis of equality of
diversity indices is true. It is shown that transformations of the data
can not be used to remedy this situation. We construct an
asymptotically correct method and illustrate its implementation using
dinosaur extinction data.},
    keywords = {multiple comparisons; diversity indices; transformations},
    timescited = {1},
    pages = {617--625},
}
 
@article{Bretz+Genz+Hothorn:BJ:2001,
    author = {F. Bretz and A. Genz and L. A. Hothorn},
    title = {On the numerical availability of multiple comparison procedures},
    journal = {Biometrical Journal},
    month = {},
    year = {2001},
    volumne = {43},
    number = {5},
    isitag = {ISI:000171069400011},
    abstract = {In the past many multiple comparison procedure were difficult to
perform. Usually, such procedures can be traced back to studentized
multiple contrast tests. Numerical difficulties restricted the use of
the exact procedures to simple, commonly balanced, designs.
Conservative approximations or simulation based approaches have been
used in the general cases. However, new efforts and results in the past
few years have led to fast and efficient computations of the underlying
multidimensional integrals. Inferences for any finite set of linear
functions of normal means are now numerically feasible. These include
all-pairwise comparisons, comparisons with a control (including
dose-response contrasts), multiple comparison with the best, etc. The
article applies the numerical progress on multiple comparisons
procedures for common balanced and unbalanced designs within the
general linear model.},
    keywords = {studentized contrast tests; numerical computation; multivariate
t-distribution},
    timescited = {8},
    pages = {645--656},
}
 
@article{Somerville+Bretz:BJ:2001,
    author = {P. N. Somerville and F. Bretz},
    title = {Obtaining critical values for simultaneous confidence intervals and multiple testing},
    journal = {Biometrical Journal},
    month = {},
    year = {2001},
    volumne = {43},
    number = {5},
    isitag = {ISI:000171069400012},
    abstract = {There are many situations where it is desired to make simultaneous
tests or give simultaneous confidence intervals for linear combinations
(contrasts) of population or treatment means. SOMERVILLE (1997, 1999)
developed algorithms for calculating the critical values for a large
class of simultaneous tests and simultaneous confidence intervals.
Fortran 90 and SAS-IML batch programs and interactive programs were
developed. These programs calculate the critical values for 15
different simultaneous confidence interval procedures (and the
corresponding simultaneous tests) and for arbitrary procedures where
the user specifies a combination of one and two sided contrasts. The
programs can also be used to obtain the constants for "step-down"
testing of multiple hypotheses. This paper gives examples of the use of
the algorithms and programs and illustrates their versatility and
generality. The designs need not be balanced, multiple covariates may
be present and there may be many missing values. The use of multiple
regression and dummy variables to obtain the required variance
covariance matrix is illustrated. Under weak normality assumptions the
methods are "exact" and make the use of approximate methods or
"simulation" unnecessary.},
    keywords = {multiple testing; multiple comparisons; simultaneous confidence
intervals; critical values},
    timescited = {1},
    pages = {657--663},
}
 
@article{Mehrotra+Li+Gilbert:Biometrics:2006,
    author = {D. V. Mehrotra and X. M. Li and P. B. Gilbert},
    title = {A comparison of eight methods for the dual-endpoint evaluation of efficacy in a proof-of-concept {HIV} vaccine trial},
    journal = {Biometrics},
    month = {SEP},
    year = {2006},
    volumne = {62},
    number = {3},
    isitag = {ISI:000240708300033},
    abstract = {To support the design of the world's first proof-of-concept (POC)
efficacy trial of a cell-mediated immunity-based HIV vaccine, we
evaluate eight methods for testing the composite null hypothesis of
no-vaccine effect on either the incidence of HIV infection or the viral
load set point among those infected, relative to placebo. The first two
methods use a single test applied to the actual values or ranks of a
burden-of-illness (BOT) outcome that combines the infection and viral
load endpoints. The other six methods combine separate tests for the
two endpoints using unweighted or weighted versions of the two-part z,
Simes', and Fisher's methods. Based on extensive simulations that were
used to design the landmark POC trial, the BOI methods are shown to
have generally low power for rejecting the composite null hypothesis
(and hence advancing the vaccine to a subsequent large-scale efficacy
trial). The unweighted Simes' and Fisher's combination methods perform
best overall. Importantly, this conclusion holds even after the test
for the viral load component is adjusted for bias that can be
introduced by conditioning on a postrandomization event (HIV
infection). The adjustment is derived using a selection bias model
based on the principal stratification framework of causal inference.},
    keywords = {burden of illness; causal inference; cell-mediated immunity; Fisher's
test; HIV vaccine; multiple endpoints; principal stratification;
selection bias; Simes' test},
    timescited = {0},
    pages = {893--900},
}
 
@article{Bretz+Pinheiro+Branson:Biometrics:2005,
    author = {F. Bretz and J. C. Pinheiro and M. Branson},
    title = {Combining multiple comparisons and modeling techniques in dose-response studies},
    journal = {Biometrics},
    month = {SEP},
    year = {2005},
    volumne = {61},
    number = {3},
    isitag = {ISI:000231689900010},
    abstract = {The analysis of data from dose-response studies has long been divided
according to two major strategies: multiple comparison procedures and
model-based approaches. Model-based approaches assume a functional
relationship between the response and the dose, taken as a quantitative
factor, according to a prespecified parametric model. The fitted model
is then used to estimate an adequate dose to achieve a desired response
but the validity of its conclusions will highly depend on the correct
choice of the a priori unknown dose-response model. Multiple comparison
procedures regard the dose as a qualitative factor and make very few,
if any, assumptions about the underlying dose-response model. The
primary goal is often to identify the minimum effective dose that is
statistically significant and produces a relevant biological effect.
One approach is to evaluate the significance of contrasts between
different dose levels, while preserving the family-wise error rate.
Such procedures are relatively robust but inference is confined to the
selection of the target dose among the dose levels under investigation.
We describe a unified strategy to the analysis of data from
dose-response studies which combines multiple comparison and modeling
techniques. We assume the existence of several candidate parametric
models and use multiple comparison techniques to choose the one most
likely to represent the true underlying dose-response curve, while
preserving the family-wise error rate. The selected model is then used
to provide inference on adequate doses.},
    keywords = {contrast test; dose finding; minimum effective dose; multiple testing},
    timescited = {3},
    pages = {738--748},
}
 
@article{Hellmich+Lehmacher:Biometrics:2005,
    author = {M. Hellmich and W. Lehmacher},
    title = {Closure procedures for monotone bi-factorial dose-response designs},
    journal = {Biometrics},
    month = {MAR},
    year = {2005},
    volumne = {61},
    number = {1},
    isitag = {ISI:000227576600032},
    abstract = {Two goals of multiple-dose factorial trials are (i) demonstrating
improved effectiveness of a fixed combination over each of its
components as well as (ii) identifying a safe and effective dose range.
The authors address both goals though with focus on the second by
closure procedures that guarantee strong control of the familywise
error rate. Two different families of null hypotheses are investigated
for bi-factorial dose-response designs that are monotone with respect
to the matrix partial order. One is suitable to find the minimum
effective dose(s) and the other one is large enough to identify the
highest effective dose step(s). Likelihood ratio tests and appropriate
multiple contrast tests are applied to an unbalanced clinical trial
example taken from Hung (2000, Statistics in Medicine 19, 2079-2087).
Full computer code written in the R language is available from the
Internet.},
    keywords = {bi-factorial design; closure procedure; dose finding; fixed
combination; likelihood ratio test; minimum effective dose; multiple
contrast test; partial matrix order},
    timescited = {0},
    pages = {269--276},
}
 
@article{Kwong+Cheung+Chan:Biometrics:2004,
    author = {K. S. Kwong and S. H. Cheung and W. S. Chan},
    title = {Multiple testing to establish superiority/equivalence of a new treatment compared with k standard treatments for unbalanced designs},
    journal = {Biometrics},
    month = {JUN},
    year = {2004},
    volumne = {60},
    number = {2},
    isitag = {ISI:000222126400022},
    abstract = {In clinical studies, multiple superiority/equivalence testing
procedures can be applied to classify a new treatment as superior,
equivalent (same therapeutic effect), or inferior to each set of
standard treatments. Previous stepwise approaches (Dunnett and Tamhane,
1997, Statistics in Medicine 16, 2489-2506; Kwong, 2001, Journal of
Statistical Planning and Inference 97, 359-366) are only appropriate
for balanced designs. Unfortunately, the construction of similar tests
for unbalanced designs is far more complex, with two major
difficulties: (i) the ordering of test statistics for superiority may
not be the same as the ordering of test statistics for equivalence; and
(ii) the correlation structure of the test statistics is not
equi-correlated but product-correlated. In this article, we seek to
develop a two-stage testing procedure for unbalanced designs, which are
very popular in clinical experiments. This procedure is a combination
of step-up and single-step testing procedures, while the familywise
error rate is proved to be controlled at a designated level.
Furthermore, a simulation study is conducted to compare the average
powers of the proposed procedure to those of the single-step procedure.
In addition, a clinical example is provided to illustrate the
application of the new procedure.},
    keywords = {coherence property; equivalent efficacy; familywise error rate;
multivariate t-distribution},
    timescited = {0},
    pages = {491--498},
}
 
@article{Hirotsu+Ohta+Hirose:Biometrics:2003,
    author = {C. Hirotsu and E. Ohta and N. Hirose and K. Shimizu},
    title = {Profile analysis of 24-hours measurements of blood pressure},
    journal = {Biometrics},
    month = {DEC},
    year = {2003},
    volumne = {59},
    number = {4},
    isitag = {ISI:000187501100019},
    abstract = {A method is proposed for classifying subjects according to their
convex, flat, or concave change patterns of 24-hours blood pressure
measurements. To obtain such a classification is useful for detecting
subjects who show abnormal change patterns and giving them appropriate
medical treatments. Therefore, an appropriate statistic is proposed for
detecting a systematic change along the time axis, as well as a
statistic with its inverse characteristic appropriate for evaluating
the noise variation. The method is based on the ratio of those two
types of statistics; it is verified to work well on real data, giving a
classification of subjects into four types of subgroups: extreme
dipper, dipper, nondipper, and inverted dipper. It also suggests that
there might be an ultra-extreme dipper subgroup.},
    keywords = {analysis of interaction; classification; convex and concave patterns;
multiple comparisons; order-restricted inference},
    timescited = {0},
    pages = {907--915},
}
 
@article{Dunson+Herring:Biometrics:2003,
    author = {D. B. Dunson and A. H. Herring},
    title = {Bayesian inferences in the {Cox} model for order-restricted hypotheses},
    journal = {Biometrics},
    month = {DEC},
    year = {2003},
    volumne = {59},
    number = {4},
    isitag = {ISI:000187501100020},
    abstract = {In studying the relationship between an ordered categorical predictor
and an event time, it is standard practice to include dichotomous
indicators of the different levels of the predictor in a Cox model. One
can then use a multiple degree-of-freedom score or partial likelihood
ratio test for hypothesis testing. Often, interest focuses on comparing
the null hypothesis of no difference to an order-restricted
alternative, such as a monotone increase across levels of a predictor.
This article proposes a Bayesian approach for addressing hypotheses of
this type. We reparameterize the Cox model in terms of a cumulative
product of parameters having conjugate prior densities, consisting of
mixtures of point masses at one, and truncated gamma densities. Due to
the structure of the model, posterior computation can proceed via a
simple and efficient Gibbs sampling algorithm. Posterior probabilities
for the global null hypothesis and subhypotheses, comparing the hazards
for specific groups, can be calculated directly from the output of a
single Gibbs chain. The approach allows for level sets across which a
predictor has no effect. Generalizations to multiple predictors are
described, and the method is applied to a study of emergency medical
treatment for stroke.},
    keywords = {categorical covariates; Gibbs sampler; Isotonic Regression;
monotonicity; multiple comparisons; proportional hazards; survival
analysis},
    timescited = {0},
    pages = {916--923},
}
 
@article{Gonen+Westfall+Johnson:Biometrics:2003,
    author = {M. Gonen and P. H. Westfall and W. O. Johnson},
    title = {Bayesian multiple testing for two-sample multivariate endpoints},
    journal = {Biometrics},
    month = {MAR},
    year = {2003},
    volumne = {59},
    number = {1},
    isitag = {ISI:000181997400009},
    abstract = {In clinical studies involving multiple variables, simultaneous tests
are often considered where both the outcomes and hypotheses are
correlated. This article proposes a multivariate mixture prior on
treatment effects, that allows positive probability of zero effect for
each hypothesis, correlations among effect sizes, correlations among
binary outcomes of zero versus nonzero effect, and correlations among
the observed test statistics (conditional on the effects). We develop a
Bayesian multiple testing procedure, for the multivariate two-sample
situation with unknown covariance structure, and obtain the posterior
probabilities of no difference between treatment regimens for specific
variables. Prior selection methods and robustness issues are discussed
in the context of a clinical example.},
    keywords = {Bayesian t-test; efficacy; model selection; multiple comparisons;
posterior probability},
    timescited = {2},
    pages = {76--82},
}
 
@article{Fritsch+Hsu:Biometrics:1999,
    author = {K. S. Fritsch and J. C. Hsu},
    title = {Multiple comparison of entropies with application to dinosaur biodiversity},
    journal = {Biometrics},
    month = {DEC},
    year = {1999},
    volumne = {55},
    number = {4},
    isitag = {ISI:000084218000049},
    abstract = {Did the biodiversity of dinosaurs decline, or did it remain more or
less constant before their mass extinction 65 million years ago?
Sheehan et al. (1991, Science, 835-839) reported that the biodiversity
of families of dinosaur species remained more or less constant
preceding their extinction, suggesting extinction due to a cataclysmic
event such as an asteroid strike. But that claim was based on the
incorrect interpretation that a large p value associated with a test of
null hypothesis of equality supports that null hypothesis. To assess
whether there is a basis for such a claim, we formulate the problem as
one of practical equivalence, in analogy to bioequivalence. We then
develop reliable practical equivalence confidence intervals for
differences of entropies by applying the bootstrap-t technique to a
nearly pivotal quantity. Confidence intervals for changes in the
biodiversity of dinosaurs are then computed, allowing the reader to
assess whether there is evidence of near constancy of dinosaur
biodiversity before extinction.},
    keywords = {biodiversity; entropy; equivalence; multiple comparisons},
    timescited = {3},
    pages = {1300--1305},
}
 
@article{Hommel+Krummenauer:Biometrics:1998,
    author = {G. Hommel and F. Krummenauer},
    title = {Improvements and modifications of {Tarone's} multiple test procedure for discrete data},
    journal = {Biometrics},
    month = {JUN},
    year = {1998},
    volumne = {54},
    number = {2},
    isitag = {ISI:000074161600023},
    abstract = {Tarone (1990, Biometrics 46, 515-522) proposed a multiple test
procedure for discrete test statistics improving the usual Bonferroni
procedure. However, Tarone's procedure is not monotone depending on the
predetermined multiple level alpha. Roth (1998, Journal of Statistical
Planning and inference, in press) developed a monotone version of
Tarone's procedure. We present a similar procedure that is both
monotone and an improvement of Tarone's proposal. Based on this
extension, we derive a step-down procedure that is a corresponding
improvement of Helm's (1979, Scandinavian Journal of Statistics 6,
65-70) sequentially rejective procedure. It is shown how adjusted
p-values can be computed for the monotone procedures. Finally, the
described ideas are applied to the concept of Ruger tests.},
    keywords = {adjusted p-values; Bonferroni procedure; discrete test statistics;
minimum attainable p-value; multiple test procedures; Ruger test;
step-down procedures; Tarone's test},
    timescited = {5},
    pages = {673--681},
}
 
@article{Liu:Biometrics:1997,
    author = {W. Liu},
    title = {Some results on step-up tests for comparing treatments with a control in unbalanced one-way layouts},
    journal = {Biometrics},
    month = {DEC},
    year = {1997},
    volumne = {53},
    number = {4},
    isitag = {ISI:000071147700029},
    abstract = {The basic problem is to compare several treatments with a control in
the standard unbalanced one-way layouts. Step-up tests were considered
by Dunnett and Tamhane (1995, Biometrics 51, 217-227). In this paper, a
method of calculating the critical values of step-up tests is proposed
so that the Type I familywise error (FWE) is controlled at a
prespecified level alpha. It is also pointed out that the equivalence
of a step-up test and the test based on the correspondingly adjusted
p-values requires implicitly a monotone property. A practical example
is used for illustration.},
    keywords = {multiple tests; type I familywise error},
    timescited = {6},
    pages = {1508--1512},
}
 
@article{Troendle:Biometrics:1996,
    author = {J. F. Troendle},
    title = {A permutational step-up method of testing multiple outcomes},
    journal = {Biometrics},
    month = {SEP},
    year = {1996},
    volumne = {52},
    number = {3},
    isitag = {ISI:A1996VF83800006},
    abstract = {This paper describes a permutational step-up multiple comparison
procedure to adjust the p values from k related hypotheses. The method
is applicable when two groups of subjects are being compared on each of
k outcomes. It is related to the step-down method of Westfall and Young
(1993, Resampling-Based Multiple Testing: Examples and Methods for
P-Value Adjustment, Volume 1) and Troendle (1995, Journal of the
American Statistical Association 90, 370-378) and is an alternative to
the analytic step-up method of Dunnett and Tamhane (1992, Journal of
the American Statistical Association. 87, 162-170), which requires a
specific distribution and correlation structure. By conditioning on the
data observed, this permutational method avoids any specific
distribution or correlation assumption. It is shown very generally that
the method asymptotically controls the familywise probability of a type
I error.},
    keywords = {adjusted p value; familywise error rate; power; step-up procedure; test
statistic},
    timescited = {14},
    pages = {846--859},
}
 
@article{Cheung+Chan:Biometrics:1996,
    author = {S. H. Cheung and W. S. Chan},
    title = {Simultaneous confidence intervals for pairwise multiple comparisons in a two-way unbalanced design},
    journal = {Biometrics},
    month = {JUN},
    year = {1996},
    volumne = {52},
    number = {2},
    isitag = {ISI:A1996UR16000007},
    abstract = {Tukey's (1953, The Problem of Multiple Comparisons, unpublished report,
Princeton University) procedure is widely used for pairwise multiple
comparisons in one-way ANOVA. It provides exact simultaneous pairwise
confidence intervals (SPCI) for balanced designs and conservative SPCI
for unbalanced designs. In this paper, we will extend Tukey's procedure
to two-way unbalanced designs. Both the exact and the conservative
methods will be introduced. The application of the new procedure is
illustrated with sample data from two experiments.},
    keywords = {familywise type I error; multivariate normal probabilities;
Tukey-Kramer procedure},
    timescited = {5},
    pages = {463--472},
}
 
@article{Tamhane+Hochberg+Dunnett:Biometrics:1996,
    author = {A. C. Tamhane and Y. Hochberg and C. W. Dunnett},
    title = {Multiple test procedures for dose finding},
    journal = {Biometrics},
    month = {MAR},
    year = {1996},
    volumne = {52},
    number = {1},
    isitag = {ISI:A1996UF29200003},
    abstract = {The problem of identifying the lowest dose level for which the mean
response differs from that at the zero dose level is considered. A
general framework for stepwise testing procedures that use contrasts
among the dose level means is proposed. Using this framework, several
new procedures are derived. These and some existing procedures,
including that of Williams (1971, Biometrics 27, 103-117; 1972,
Biometrics 28, 519-531), are compared analytically and by an extensive
simulation study for the normal theory balanced one-way layout case. It
is pointed out that the procedures based on the so-called step and
basin contrasts proposed by Ruberg (1989, Journal of American
Statistical Association 84, 816-822) have excessively high type I
familywise error rates (FWEs) and, hence, they should not be used. Some
findings of the simulation study are as follows: For monotone dose mean
configurations, Williams' procedure and two step-down test procedures
based on Helmert and linear contrasts offer the best performance. For
nonmonotone dose mean configurations, the performance of Williams'
procedure does degrade somewhat, but the other two procedures are still
the best. For more complex designs, a simple step-down test procedure
that uses any ct-level tests (not necessarily t-tests) to compare each
dose level with the zero dose level controls the FWE and is the only
alternative available, but its power is rather low, especially under
nommonotone configurations. Step-up procedures are generally dominated
by step-down procedures when the same contrasts are used although the
differences are not great.},
    keywords = {dose-response function; familywise error rate; Monte Carlo simulations;
multiple comparison procedures; multivariate t-distribution; stepwise
testing procedures},
    timescited = {48},
    pages = {21--37},
}
 
@article{Hannig+Marron:JASA:2006,
    author = {J. Hannig and J. S. Marron},
    title = {Advanced distribution theory for {SiZer}},
    journal = {Journal of the American Statistical Association},
    month = {JUN},
    year = {2006},
    volumne = {101},
    number = {474},
    isitag = {ISI:000238033200007},
    abstract = {SiZer is a powerful method for exploratory data analysis. In this
article approximations to the distributions underlying the simultaneous
statistical inference are investigated, and large improvements are made
in the approximation using extreme value theory. This results in
improved size, and also in an improved global inference version of
SiZer. The main points are illustrated with real data and simulated
examples.},
    keywords = {extreme value theory; kernel smoothing; multiple testing adjustment;
SiZer},
    timescited = {0},
    pages = {484--499},
}
 
@article{Finner+Strassburger:JASA:2006,
    author = {H. Finner and K. Strassburger},
    title = {On delta-equivalence with the best in k-sample models},
    journal = {Journal of the American Statistical Association},
    month = {JUN},
    year = {2006},
    volumne = {101},
    number = {474},
    isitag = {ISI:000238033200027},
    abstract = {In recent work we introduced a general, a weak, and a strong
partitioning principles for the construction of multiple decision
procedures as multiple testing or selection procedures. Partitioning
principles can be viewed as natural extensions of the closure principle
and sometimes yield more powerful decision procedures. In this article
we consider the problem of establishing equivalence with the best with
respect to k treatment means, where equivalence is defined in terms of
a threshold value delta > 0. We reformulate the original selection
problem as a multiple testing problem and develop various step-down and
step-up procedures by applying the closure principle and partitioning
principles. The new step-down procedure is shown to provide a uniform
improvement over procedures currently in use. Moreover, we propose some
projection methods that yield confidence intervals being compatible
with stepwise tests and selection procedures.},
    keywords = {bioequivalence; equivalence with the best; formal closure principle;
multiple comparisons; multiple comparisons with control; multiple
comparisons with the best; sample size determination; strong
partitioning principle; subset selection; weak partitioning principle},
    timescited = {0},
    pages = {737--746},
}
 
@article{Romano+Wolf:JASA:2005,
    author = {J. R. Romano and M. Wolf},
    title = {Exact and approximate stepdown methods for multiple hypothesis testing},
    journal = {Journal of the American Statistical Association},
    month = {MAR},
    year = {2005},
    volumne = {100},
    number = {469},
    isitag = {ISI:000233311100015},
    abstract = {Consider the problem of testing k hypotheses simultaneously. In this
article we discuss finite- and large-sample theory of stepdown methods
that provide control of the familywise error rate (FWE). To improve on
the Bonferroni method or on Holm's stepdown method, Westfall and Young
made effective use of resampling to construct stepdown methods that
implicitly estimate the dependence structure of the test statistics.
However, their methods depend on an assumption known as "subset
pivotality." Our goal here is to construct general stepdown methods
that do not require such an assumption. To accomplish this, we take a
close look at what makes stepdown procedures work; a key component is a
monotonicity requirement of critical values. By imposing monotonicity
on estimated critical values (which is not an assumption on the model
but rather is an assumption on the method), we show how to construct
stepdown tests that can be applied in a stagewise fashion so that at
most k tests need to be computed. Moreover, at each stage, an
intersection test that controls the usual probability of a type 1 error
is calculated, which allows us to draw on an enormous resampling
literature as a general means of test construction. In addition, it is
possible to carry out this method using the same set of resamples (or
subsamples) for each of the intersection tests.},
    keywords = {bootstrap; familywise error rate; multiple testing; permutation test;
randomization test; stepdown procedure; subsampling},
    timescited = {1},
    pages = {94--108},
}
 
@article{Liu+Jamshidian+Zhang:JASA:2004,
    author = {W. Liu and M. Jamshidian and Y. Zhang},
    title = {Multiple comparison of several linear regression models},
    journal = {Journal of the American Statistical Association},
    month = {JUN},
    year = {2004},
    volumne = {99},
    number = {466},
    isitag = {ISI:000221572500009},
    abstract = {Research on multiple comparison during the past 50 years or so has
focused mainly on the comparison of several population means. Several
years ago. Spurrier considered the multiple comparison of several
simple linear regression lines. He constructed simultaneous confidence
bands for all of the contrasts of the simple linear regression lines
over the entire range (-infinity, infinity) when the models have the
same design matrices. This article extends Spurrier's work in several
directions. First. multiple linear regression models are considered and
the design matrices are allowed to be different. Second. the predictor
variables are either unconstrained or constrained to finite intervals.
Third, the types of comparison allowed can be very flexible, including
pairwise. many-one, and successive. Two simulation methods are proposed
for the calculation of critical constants. The methodologies are
illustrated with examples.},
    keywords = {drug stability testing; linear regression; multiple comparisons;
simultaneous inference; statistical simulation},
    timescited = {3},
    pages = {395--403},
}
 
@article{Tamhane+Logan:JASA:2002,
    author = {A. C. Tamhane and B. R. Logan},
    title = {Multiple test procedures for identifying the minimum effective and maximum safe doses of a drug},
    journal = {Journal of the American Statistical Association},
    month = {MAR},
    year = {2002},
    volumne = {97},
    number = {457},
    isitag = {ISI:000173997500031},
    abstract = {We address the problem of determining the therapeutic window of a drug
by finding its minimum effective and maximum safe doses (MINED and
MAXSD), The MINED is the lowest dose that exceeds the mean efficacy of
the zero dose by a specified threshold, and the MAXSD is the highest
dose that does not exceed the mean toxicity of the zero dose by a
specified threshold. Step-down multiple test procedures are proposed to
identify the MINED and MAXSD assuming a bivariate normal model. These
procedures control the type I familywise error probability of declaring
any ineffective dose as effective or any unsafe dose as safe at a
prespecified level alpha. A new multivariate t-distribution is
introduced whose critical points are required to implement the exact
normal theory procedures. Because these critical points depend on the
unknown correlation coefficient between the efficacy and safety
variables, the Bonferroni method is proposed as an alternative, which
amounts to separately testing for efficacy and safety, each at type I
familywise error rate of alpha/2. The bootstrap versions of the exact
normal theory procedures provide an approximate way to jointly test for
efficacy and safety without the knowledge of the correlation
coefficient, as well as to relax the bivariate normality assumption.
The Bonferroni and bootstrap procedures are compared in a simulation
study. It is shown that significant power gains are achieved by jointly
testing for both efficacy and safety using bootstrap procedures, Coded
data from an arthritis drug trial are analyzed to illustrate the
procedures.},
    keywords = {bootstrap method; closed testing procedure; dose finding; familywise
error rate; multiple comparisons; multivariate t-distribution;
step-down procedure; therapeutic window},
    timescited = {4},
    pages = {293--301},
}
 
@article{Tamhane+Dunnett+Green:JASA:2001,
    author = {A. C. Tamhane and C. W. Dunnett and J. W. Green and J. D. Wetherington},
    title = {Multiple test procedures for identifying the maximum safe dose},
    journal = {Journal of the American Statistical Association},
    month = {SEP},
    year = {2001},
    volumne = {96},
    number = {455},
    isitag = {ISI:000170729300006},
    abstract = {we consider dose response studies for safety assessment of crop
protection compounds and drugs, and we offer a hypothesis testing
approach for identifying the maximum dose level that is guaranteed to
be safe with preassigned confidence. The focus is on step-down (SD)
multiple test procedures for identifying the maximum safe dose. We
propose two classes of contrasts among the dose means as test
statistics for these procedures: pairwise contrasts (PC) and Helmert
contrasts (HC). The first procedure (SD2PC) consists of a sequence of
ordinary t tests and is thus easy to apply, but it can have very low
power for certain step response functions. The second procedure (SD1HC)
does not suffer from this drawback, but it requires a weak monotonicity
assumption for its mathematical validity. The powers of SD2PC and SD1HC
are studied via Monte Carlo simulation. We recommend SD2PC for linear
response functions and SD1HC for step response functions. The
procedures are illustrated by applying them to data from an aquatic
toxicity laboratory experiment conducted to assess the safe level of a
pesticide.},
    keywords = {dose response; familywise error rate; minimum unsafe dose; multiple
comparisons; multivariate t-distribution; step-down multiple testing
procedure; toxicology},
    timescited = {6},
    pages = {835--843},
}
 
@article{Spurrier:JASA:1999,
    author = {J. D. Spurrier},
    title = {Exact confidence bounds for all contrasts of three or more regression lines},
    journal = {Journal of the American Statistical Association},
    month = {JUN},
    year = {1999},
    volumne = {94},
    number = {446},
    isitag = {ISI:000081058500017},
    abstract = {It is desired to compare k greater than or equal to 3 treatments. Under
the assumption of lid normal errors, it is well known that the Scheffe
method produces exact simultaneous confidence bounds for all contrasts
of the treatment means. Furthermore, it is known that the Scheffe
method is conservative when one desires confidence bounds for a
specific subset of contrasts of means. Exact methods, such as those due
to Tukey and Dunnett, yield tighter bounds than the Scheffe method for
specific subsets of contrasts of means. in this article, multiple
comparisons of the k treatments are done not in terms of their means,
but rather in terms of a parametric function. The parametric function
of interest is the simple linear regression model, E(Y\x). Ir, is
desired to find simultaneous confidence bounds fur all contrasts of the
k simple linear regression models. Although the Scheffe method can be
used to find such bounds, this is extremely conservative. The
union-intersection method is used to develop simultaneous confidence
bounds for these contrasts under the assumption of equal design
matrices for each treatment. The method is based on a pivotal quantity
whose distribution function is a linear combination of F distribution
functions. Thus probability points can be computed using standard
computing packages. The Scheffe bounds are about 5% wider than the
exact bounds for k = 3 and about 13% wider for k = 6.},
    keywords = {multiple comparison : Scheffe method; simple linear regression;
simultaneous confidence; union intersection},
    timescited = {9},
    pages = {483--488},
}
 
@article{Westfall:JASA:1998,
    author = {P. Westfall},
    title = {Multiple testing of general contrasts using logical constraints and correlations (vol 92, pg 299, 1997)},
    journal = {Journal of the American Statistical Association},
    month = {MAR},
    year = {1998},
    volumne = {93},
    number = {441},
    isitag = {ISI:000072355300041},
    abstract = {NA},
    keywords = {NA},
    timescited = {0},
    pages = {413--413},
}
 
@article{Tang+Lin:JASA:1997,
    author = {D. I. Tang and S. P. Lin},
    title = {An approximate likelihood ratio test for comparing several treatments to a control},
    journal = {Journal of the American Statistical Association},
    month = {SEP},
    year = {1997},
    volumne = {92},
    number = {439},
    isitag = {ISI:A1997XU87800037},
    abstract = {Some parametric tests for comparing several treatments to a control are
examined. Those tests developed earlier tend to rest on a single
principle: simplicity or power; those developed later attempt to fill
the gap. We propose a new test that represents another such attempt.
The basic idea is to find a simple statistic that is a good
approximation to the likelihood ratio statistic. This leads to a power
function similar to that of the likelihood ratio test, which is optimal
among the available competitors. Like the orthogonal contrast test, the
new test is built on an orthogonal relationship, resulting in a
relatively simple null distribution that depends on the sample sizes
only through their total. Thus critical values can be easily computed
and a detailed listing results in only a moderately large table.
Computing the statistic is elementary when the sample sizes of the new
treatments are equal; otherwise, some matrix operations are needed. A
simple procedure is given to estimate the sample size required to
achieve a given power level. To compete with Dunnett's test in terms of
pairwise comparison, the new test (or any of the other tests) can be
applied according to the closed testing procedure. In this setting the
new test is compared to Dunnett's test by simulation.},
    keywords = {closed testing; cone hypothesis; Dunnett's test; multiple comparisons;
multivariate one-sided testing; orthant hypothesis},
    timescited = {12},
    pages = {1155--1162},
}
 
@article{Westfall:JASA:1997,
    author = {P. H. Westfall},
    title = {Multiple testing of general contrasts using logical constraints and correlations},
    journal = {Journal of the American Statistical Association},
    month = {MAR},
    year = {1997},
    volumne = {92},
    number = {437},
    isitag = {ISI:A1997WL26500031},
    abstract = {Use of logical constraints among hypotheses and correlations among test
statistics can greatly improve the power of step-down tests. An
algorithm for uncovering these logically constrained subsets in a given
dataset is described. The multiple testing results are summarized using
adjusted p values, which incorporate the relevant dependence structures
and logical constraints.,These adjusted p values are computed
consistently and efficiently using a generalized least squares hybrid
of simple and control-variate Monte Carlo methods, and the results are
compared to alternative stepwise testing procedures.},
    keywords = {adjusted p value; control variate; linear model; Monte Carlo; multiple
comparisons; simultaneous inference},
    timescited = {20},
    pages = {299--306},
}
 
@article{McCann+Edwards:JASA:1996,
    author = {M. McCann and D. Edwards},
    title = {A path length inequality for the multivariate-t distribution, with applications to multiple comparisons},
    journal = {Journal of the American Statistical Association},
    month = {MAR},
    year = {1996},
    volumne = {91},
    number = {433},
    isitag = {ISI:A1996UB27200020},
    abstract = {This article presents a new inequality for the multivariate-t
distribution, which implies a new method for multiple comparisons whose
foundation rests on a recent inequality due to Naiman. The new method
is promising in view of the fact that it utilizes information
(estimator intercorrelations) ignored by the most widely used multiple
comparison methods yet is not computationally prohibitive, requiring
only the numerical evaluation of a single one-dimensional integral. In
this article the validity of the new method in the normal-theoretic
general linear model is established, and efficiency studies relative to
the methods of Scheffe, Bonferroni, Sidak, and Hunter-Worsley are
presented. The new method is shown to always improve on Scheffe's
method. The new method is also shown to perform well; that is, to lead
to a smaller critical point than its competitors, with low degrees of
freedom. But the method is not as efficient as the Hunter-Worsley
method for high degrees of freedom. In addition, the method appears to
increase in relative efficiency as the number of comparisons increases
relative to the rank of the correlation matrix of the estimators.},
    keywords = {confidence intervals; family-wise error; Naiman's inequality;
simultaneous inference},
    timescited = {9},
    pages = {211--216},
}
 
@article{TROENDLE:JASA:1995,
    author = {J. F. TROENDLE},
    title = {A STEPWISE RESAMPLING METHOD OF MULTIPLE HYPOTHESIS-TESTING},
    journal = {Journal of the American Statistical Association},
    month = {MAR},
    year = {1995},
    volumne = {90},
    number = {429},
    isitag = {ISI:A1995QH03000041},
    abstract = {This article introduces a method of multiple hypothesis testing that
combines the idea of sequential multiple testing procedures with the
structure of resampling methods. The method can be seen as an
alternative to the analytic method of Dunnett and Tamhane, which
requires a specific distributional form. Resampling incorporates the
covariance structure of the data without the need for distributional
assumptions. Recent work by Westfall and Young has shown that a
step-down resampling method is asymptotically consistent when adjusted
p values can be obtained exactly for continuous data. This article
shows that in the case of a comparison of two groups on multiple
outcomes, those results are generalizable to discrete data where exact
adjusted p values are not available. It is shown that the method
asymptotically attains the desired level for controlling the
experimentwise probability of a type I error.},
    keywords = {EXPERIMENTWISE; P VALUE; TEST STATISTIC; TYPE I ERROR},
    timescited = {25},
    pages = {370--378},
}
 
@article{Liu+Jamshidian+Zhang:JSPI:2007,
    author = {W. Liu and M. Jamshidian and Y. Zhang and F. Bretz and X. L. Han},
    title = {Some new methods for the comparison of two linear regression models},
    journal = {Journal of Statistical Planning and Inference},
    month = {JAN 1},
    year = {2007},
    volumne = {137},
    number = {1},
    isitag = {ISI:000241099000006},
    abstract = {The frequently used approach to the comparison of two linear regression
models is to use the partial F test. It is pointed out in this paper
that the partial F test has in fact a naturally associated two-sided
simultaneous confidence band, which is much more informative than the
test itself. But this confidence band is over the entire range of all
the covariates. As regression models are true or of interest often only
over a restricted region of the covariates, the part of this confidence
band outside this region is therefore useless and to ensure 1 - alpha
simultaneous coverage probability is therefore wasteful of resources.
It is proposed that a narrower and hence more efficient confidence band
over a restricted region of the covariates should be used. The critical
constant required in the construction of this confidence band can be
calculated by Monte Carlo simulation. While this two-sided confidence
band is suitable for two-sided comparisons of two linear regression
models, a more efficient one-sided confidence band can be constructed
in a similar way if one is only interested in assessing whether the
mean response of one regression model is higher (or lower) than that of
the other in the region. The methodologies are illustrated with two
examples. (c) 2005 Elsevier B.V. All rights reserved.},
    keywords = {confidence bands; linear regression; multiple comparisons; simultaneous
inference; statistical simulation},
    timescited = {0},
    pages = {57--67},
}
 
@article{Tamhane+Shi+Strassburger:JSPI:2006,
    author = {A. C. Tamhane and K. Shi and K. Strassburger},
    title = {Power and sample size determination for a stepwise test procedure for finding the maximum safe dose},
    journal = {Journal of Statistical Planning and Inference},
    month = {JUL 1},
    year = {2006},
    volumne = {136},
    number = {7},
    isitag = {ISI:000236564400013},
    abstract = {This paper addresses the problem of power and sample size calculation
for a stepwise multiple test procedure (SD2PC) proposed in Tamhane et
al. [2001. Multiple test procedures for identifying the maximum safe
dose. J. Amer. Statist. Assoc. 96, 835-843] to identify the maximum
safe dose of a compound. A general expression for the power of this
procedure is derived. It is used to find the minimum overall power and
minimum power under the constraint that the dose response function is
bounded from below by a linear response function. It is shown that the
two minima are attained under step and linear response functions,
respectively. The sample sizes necessary on the zero dose control and
each of the positive doses to guarantee a specified power requirement
are calculated under these two least favorable configurations. A
technique involving a continuous approximation to the sample sizes is
used to reduce the number of quantities that need to be tabled, and to
derive the asymptotically optimal allocation of the total. sample size
between the zero dose and the positive doses. An example is given to
illustrate use of the tables. Extensions of the basic formulation are
noted. (c) 2005 Elsevier B.V. All rights reserved.},
    keywords = {design of dose-response experiments; multiple testing; multivariate
normal distribution; toxicology},
    timescited = {0},
    pages = {2163--2181},
}
 
@article{Bortnick+Dean+Hsu:JSPI:2005,
    author = {S. M. Bortnick and A. M. Dean and J. C. Hsu},
    title = {Efficiency of block designs for simultaneous comparison of two test treatments with a control},
    journal = {Journal of Statistical Planning and Inference},
    month = {FEB 15},
    year = {2005},
    volumne = {129},
    number = {1-2},
    isitag = {ISI:000226222300008},
    abstract = {In an experiment for comparing two test treatments with a control
treatment, simultaneous confidence bounds for the amount by which each
test treatment differs from the control is generally required. When the
experiment is arranged as a block design, the optimal allocation of
experimental units within the blocks to the individual test treatments
and to the control needs to be determined. The optimality criterion of
interest is the minimization of the expected average allowance (EAA) or
the expected maximum allowance (EMA), where an allowance represents the
"plus and/or minus" attached to point estimates and is the product of a
standard error and the critical value. Lower bounds for the EAA and EMA
values are provided for both one-sided and two-sided confidence
intervals. A search algorithm for obtaining efficient designs is
described. (C) 2004 Elsevier B.V. All rights reserved.},
    keywords = {block design; simultaneous confidence intervals; Dunnett method;
multiple comparisons; treatment versus control; optimal design},
    timescited = {1},
    pages = {109--124},
}
 
@article{Tamhane+Westfall:JSPI:2004,
    author = {A. C. Tamhane and P. H. Westfall},
    title = {Special issue on multiple comparisons - {Preface}},
    journal = {Journal of Statistical Planning and Inference},
    month = {OCT 1},
    year = {2004},
    volumne = {125},
    number = {1-2},
    isitag = {ISI:000223388000001},
    abstract = {NA},
    keywords = {NA},
    timescited = {0},
    pages = {1--1},
}
 
@article{Pollard+vanderLaan:JSPI:2004,
    author = {K. S. Pollard and M. J. van der Laan},
    title = {Choice of a null distribution in resampling-based multiple testing},
    journal = {Journal of Statistical Planning and Inference},
    month = {OCT 1},
    year = {2004},
    volumne = {125},
    number = {1-2},
    isitag = {ISI:000223388000007},
    abstract = {This paper investigates different choices of test statistic null
distribution for resampling-based multiple testing in the context of
single parameter hypotheses. We show that the test statistic null
distribution for strongly controlling type I error may be obtained by
projecting the true test statistic distribution onto the space of mean
zero distributions. For common choices of test statistics, this
distribution is asymptotically multivariate normal with the covariance
of the vector influence curve for the parameter estimator. Applying the
ordinary non-parametric or model-based bootstrap to mean zero centered
test statistics produces an estimated test statistic null distribution
which provides asymptotic strong control. In contrast, the usual
practice of obtaining an estimated test statistic null distribution via
an estimated data null distribution (e.g. null restricted bootstrap)
only provides an asymptotically correct test statistic null
distribution if the covariance of the vector influence curve is the
same under the chosen data null distribution as under the true data
distribution. This condition is the formal analogue of the subset
pivotality condition (Westfall and Young, Resampling-based Multiple
Testing: Examples and Methods for p-value adjustment, Wiley, New York,
1993). We demonstrate the use of our proposed ordinary bootstrap null
distribution with a single-step multiple testing method which is
equivalent to constructing an error-specific confidence region for the
true parameter and checking if it contains the hypothesized value. We
also study the two sample problem and show that the permutation method
produces an asymptotically correct null distribution if (i) the sample
sizes are equal or (ii) the populations have the same covariance
structure. (C) 2004 Elsevier B.V. All rights reserved.},
    keywords = {multiple testing; strong control; type I error; permutation; bootstrap},
    timescited = {6},
    pages = {85--100},
}
 
@article{Lin+Lee+Peng:JSPI:2002,
    author = {L. Lin and C. I. C. Lee and J. N. Peng},
    title = {Max-min multiple comparison procedure for isotonic dose-response curves},
    journal = {Journal of Statistical Planning and Inference},
    month = {SEP 1},
    year = {2002},
    volumne = {107},
    number = {1-2},
    isitag = {ISI:000178061800008},
    abstract = {Suppose (Y) over bar (1), (Y) over bar (2),..., (Y) over bar (k) are
normal random variables with ordered means mu(1) less than or equal to
mu(2) less than or equal to ... less than or equal to mu(k). simple
novel procedure that modifies Tukey's studentized range technique is
proposed for constructing simultaneous confidence intervals for
pairwise comparisons of means pi by utilizing the ordering of pi. The
procedure makes substantial improvement over its predecessor. (C) 2002
Elsevier Science B.V. All rights reserved.},
    keywords = {isotonic regression curve; simultaneous confidence intervals;
studentized range technique},
    timescited = {0},
    pages = {133--141},
}
 
@article{Kuriki+Shimodaira+Hayter:JSPI:2002,
    author = {S. Kuriki and H. Shimodaira and T. Hayter},
    title = {On the isotonic range statistic for testing against an ordered alternative},
    journal = {Journal of Statistical Planning and Inference},
    month = {JUL 1},
    year = {2002},
    volumne = {105},
    number = {2},
    isitag = {ISI:000176342400005},
    abstract = {Consider the balanced one-way layout for comparing k treatment effects
mu(i), 1 less than or equal to i less than or equal to k. Marcus
(Biometrika 63 (1976) 177) considers a test procedure for testing the
null hypothesis H-0: mu(1) = mu(2) = (...) = mu(k) against the simple
ordered alternative H-A: mu(1) less than or equal to mu(2) less than or
equal to (...) less than or equal to mu(k) with at least one strict
inequality based upon the range (&mu;) over cap (k) - (&mu;) over cap
(1) of the isotonic estimates of the treatment effects. This test
statistic was originally proposed in Williams (Biometrics 27 (1971)
103) and is sometimes referred to as the modified Williams statistic.
It has many useful applications in biostatistical studies. In this
article, we present an algorithm for calculating the distribution
function of this isotonic range statistic for a general number of
treatments k using recursive integration techniques and we provide
tables of critical points for this test procedure. This allows the full
implementation of this test procedure. We also show how this procedure
can be used to construct a set of simultaneous confidence intervals for
a set of monotone contrasts of the treatment effects and compare it
with other multiple comparisons procedures. (C) 2001 Elsevier Science
B.V. All rights reserved.},
    keywords = {analysis of variance; order restricted inference; isotonic estimates;
multiple comparisons; recursive integration; modified Williams
statistic; simultaneous inference; monotone contrasts},
    timescited = {2},
    pages = {347--362},
}
 
@article{Chen+Chi:JSPI:2000,
    author = {Y. I. Chen and Y. C. Chi},
    title = {Multiple comparisons between successive treatments for randomly right-censored survival data},
    journal = {Journal of Statistical Planning and Inference},
    month = {JAN 1},
    year = {2000},
    volumne = {83},
    number = {1},
    isitag = {ISI:000084148800010},
    abstract = {In this paper we are concerned with the problem of comparing adjacent
ordered treatments in a one-way layout where survival data are subject
to random right censorship. Multiple testing procedures based on
two-sample statistics, each comparing an individual treatment with the
previous one, are proposed for determining the pattern of the treatment
effects. The two-sample statistics under consideration are weighted
logrank statistics (Fleming and Harrington, 1991, Counting Process and
Survival Analysis. Wiley, New York) and weighted Kaplan-Meier
statistics (Pepe and Fleming, 1989. Biometrics 45, 497-507; 1991. J.
Roy. Statist, Sec. B 53, 341-352). An illustrated numerical example is
reported. Finally, the comparative results of a Monte Carlo error rate
and power study for small sample sizes are presented. (C) 2000 Elsevier
Science B.V. All rights reserved. MSC: 62J15; 62N05.},
    keywords = {Monte Carlo study; multiple comparisons; one-way layout; right-censored
data},
    timescited = {0},
    pages = {137--151},
}
 
@article{Benjamini+Hothorn+Sen:JSPI:1999,
    author = {Y. Benjamini and L. Hothorn and P. K. Sen},
    title = {Special issue on multiple comparisons - {Preface}},
    journal = {Journal of Statistical Planning and Inference},
    month = {DEC 1},
    year = {1999},
    volumne = {82},
    number = {1-2},
    isitag = {ISI:000083580500001},
    abstract = {NA},
    keywords = {NA},
    timescited = {3},
    pages = {1--4},
}
 
@article{Gut+Schwabe:JSPI:1999,
    author = {A. Gut and R. Schwabe},
    title = {Some remarks on repeated significance tests for linear contrasts},
    journal = {Journal of Statistical Planning and Inference},
    month = {DEC 1},
    year = {1999},
    volumne = {82},
    number = {1-2},
    isitag = {ISI:000083580500003},
    abstract = {We review some results obtained in an earlier paper on the relation
between some standard multidimensional test statistics and their
corresponding one-dimensional versions in a sequential setup. One
conclusion is that, in general, no one-dimensional (marginal) null
hypothesis can be rejected even though the multidimensional null
hypothesis is. An alternative method based on a multiple maximum
modulus test is proposed with a somewhat better conclusion. The results
are extended to the case of general linear contrasts, in particular to
pairwise comparisons. (C) 1999 Elsevier Science B.V. All rights
reserved. MSC: primary: 62J15; 62L10; secondary: 60F05; 60F15; 60G40;
60G50.},
    keywords = {log-likelihood; marginal test statistic; multiple test; linear
contrast; pairwise comparison; stopping time; law of large numbers;
central limit theorem},
    timescited = {0},
    pages = {25--34},
}
 
@article{Tamhane+Dunnett:JSPI:1999,
    author = {A. C. Tamhane and C. W. Dunnett},
    title = {Stepwise multiple test procedures with biometric applications},
    journal = {Journal of Statistical Planning and Inference},
    month = {DEC 1},
    year = {1999},
    volumne = {82},
    number = {1-2},
    isitag = {ISI:000083580500005},
    abstract = {We provide an overview of the recent developments in normal theory
stepwise multiple test procedures for non-hierarchical families and
describe several biometric applications where these procedures are
useful. (C) 1999 Elsevier Science B.V. All rights reserved. MSC: 62J15;
62P10.},
    keywords = {multiple comparisons; stepwise test procedures; familywise error rate;
biometric applications},
    timescited = {3},
    pages = {55--68},
}
 
@article{Koch+Hothorn:JSPI:1999,
    author = {H. F. Koch and L. A. Hothorn},
    title = {Exact unconditional distributions for dichotomous data in many-to-one comparisons},
    journal = {Journal of Statistical Planning and Inference},
    month = {DEC 1},
    year = {1999},
    volumne = {82},
    number = {1-2},
    isitag = {ISI:000083580500007},
    abstract = {The exact conditional distribution of a statistic for the many-to-one
design with dichotomous response variables was firstly given by
Williams (1988). His approach is expanded to other maximum statistics,
and their exact conditional distributions are compared. As an
alternative to the conditional approach, the exact unconditional
binomial distribution is presented for two maximum statistics. For
these distributions algorithms are described to compute the exact
unconditional p-values and critical values. As an application of the
exact unconditional distribution, a new simultaneous step-down
procedure is suggested. This procedure is based on the exact
unconditional distribution and is compared to the alpha-adjustment
procedure according to Bonferroni-Holm and Hommel when p-values result
from Fisher's exact test and Barnard's test. (C) 1999 Elsevier Science
B.V. All rights reserved. MSC: 62J15; 62E15.},
    keywords = {many-to-one design; binary data; exact unconditional test; step-down
procedure},
    timescited = {5},
    pages = {83--99},
}
 
@article{Dilba+Bretz+Hothorn:SiM:2006,
    author = {G. Dilba and F. Bretz and L. A. Hothorn and V. Guiard},
    title = {Power and sample size computations in simultaneous tests for non-inferiority based on relative margins},
    journal = {Statistics in Medicine},
    month = {APR 15},
    year = {2006},
    volumne = {25},
    number = {7},
    isitag = {ISI:000236528500004},
    abstract = {In this paper, we address the problem of calculating power and sample
sizes associated with simultaneous tests for non-inferiority. We
consider the case of comparing several experimental treatments with an
active control. The approach is based on the ratio view, where the
common non-inferiority margin is chosen to be some percentage of the
mean of the control treatment. Two power definitions in multiple
hypothesis testing, namely, complete power and minimal power, are used
in the computations. The sample sizes associated with the ratio-based
inference are also compared with that of a comparable inference based
on the difference of means for various scenarios. It is found that the
sample size required for ratio-based inferences is smaller than that of
difference-based inferences when the relative non-inferiority margin is
less than one and when large response values indicate better treatment
effects. The results are illustrated with examples. Copyright (c) 2005
John Wiley & Sons, Ltd.},
    keywords = {ratio-to-control; multiple comparison; least favourable configuration;
non-central t; non-inferiority},
    timescited = {1},
    pages = {1131--1147},
}
 
@article{Moerkerke+Goetghebeur+VanSteen:SiM:2005,
    author = {B. Moerkerke and E. Goetghebeur and K. Van Steen and S. Van Belle and V. Cocquyt},
    title = {Permutation based methods for comparing quality of life between observed treatments},
    journal = {Statistics in Medicine},
    month = {DEC 30},
    year = {2005},
    volumne = {24},
    number = {24},
    isitag = {ISI:000234284800026},
    abstract = {Quality of life is becoming an important outcome for the comparison of
aggressive therapies. To measure quality of life (QOL), questionnaires
have been designed that ask patients about symptoms and functionality
in several aspects of daily life. Primary analyses of such
questionnaires typically focus on a summary statistic, such as a sum
score or a single global question. This avoids inflated type I errors
or loss of power due to multiple testing of individual items. In
return, specific questions and answers that initially mattered to the
patient may unfortunately get buried. To avoid reduced specificity and
interpretability for both patients and physicians, we propose to also
analyse all original questions. In this paper, we seek to detect items
of the QOL questionnaire that differ significantly over observed
treatments even in the face of multiple testing. We sequentially build
a model that combines features which additionally discriminate between
treatments. To achieve this, we draw on insights gained in the field of
statistical genetics where one is often confronted with a vast amount
of predictors, e.g. of a genotypic nature. Specifically, we adopt a
permutation based approach to evaluate the null distribution of the
maximum of many correlated test statistics and use it to build a
regression model that explains QOL differences between treatment arms.
We apply the new methodology to analyse QOL data in an observational
study of four different treatments of breast cancer. We discover that a
single question captures most of the observed treatment differences in
this population. Copyright (c) 2005 John Wiley & Sons, Ltd.},
    keywords = {quality of life; permutation tests; multiple testing; breast cancer;
sequential selection},
    timescited = {0},
    pages = {4055--4066},
}
 
@article{Troendle:SiM:2005,
    author = {J. F. Troendle},
    title = {Multiple comparisons between two groups on multiple {Bernoulli} outcomes while accounting for covariates},
    journal = {Statistics in Medicine},
    month = {DEC 15},
    year = {2005},
    volumne = {24},
    number = {23},
    isitag = {ISI:000233343700004},
    abstract = {The problem of adjusting for multiplicity when one has multiple outcome
variables can be handled quite nicely by step-down permutation tests.
More difficult is the problem when one wants an analysis of each
outcome variable to be adjusted for some covariates and the outcome
variables are Bernoulli. Special permutations can be used where the
outcome vectors are permuted within each strata of the data defined by
the levels of the (made discrete) covariates. This method is described
and shown to control the familywise error rate at any prespecified
level. The method is compared through simulation to a vector bootstrap
approach, also using a step-down testing procedure. It is seen that the
method using permutations within strata is superior to the vector
bootstrap in terms of error control and power. The method is
illustrated on a data set of 55 minor malformations of babies of
diabetic and non-diabetic mothers. Published in 2005 by John Wiley &
Sons, Ltd.},
    keywords = {bootstrap; discrete; familywise error; logistic model; permutation},
    timescited = {0},
    pages = {3581--3591},
}
 
@article{Troendle+Liu+Wu:SiM:2005,
    author = {J. F. Troendle and A. Y. Liu and C. Q. Wu and K. F. Yu},
    title = {Sequential testing for efficacy in clinical trials with non-transient effects},
    journal = {Statistics in Medicine},
    month = {NOV 15},
    year = {2005},
    volumne = {24},
    number = {21},
    isitag = {ISI:000232735700001},
    abstract = {This paper describes a new type of sequential testing for clinical
trials. The sequential nature of the data is not from additional
patients, but rather from longer follow-up times. At each analysis, the
null hypothesis that all treatments are equivalent in effect on the
Outcome after that amount of time is tested. The trial might still have
staggered entry or not, but the key feature is that a different
statistical hypothesis is tested at each analysis. It is assumed that
any effect of treatment is non-transient, allowing a conclusion to be
drawn in favour of one treatment or the other based on a difference at
a single follow-up time. It is shown that a general method based on the
Bonferroni inequality can be used to obtain critical cutpoints for
sequential testing, that controls the chance of a type I error for the
clinical decision. This method is applicable regardless of the test
used at each analysis. In the case of a two-armed trial with a Gaussian
outcome variable, it is shown how simulation can be used to obtain
critical cutpoints that maintain the chance of a type I error for the
clinical decision. The methods are compared by Monte-Carlo simulation,
and it is seen that in most practical cases the Bonferroni method is
not very conservative. The Bonferroni procedure is illustrated on the
results of a real clinical trial of Pirfenidone on pulmonary fibrosis
in Hermansky-Pudlak Syndrome. Published in 2005 by John Wiley & Sons,
Ltd.},
    keywords = {Bonferroni; familywise; longitudinal; multiple testing; sequential},
    timescited = {0},
    pages = {3239--3250},
}
 
@article{Jung+Owzar+George:SiM:2005,
    author = {S. H. Jung and K. Owzar and S. L. George},
    title = {A multiple testing procedure to associate gene expression levels with survival},
    journal = {Statistics in Medicine},
    month = {OCT 30},
    year = {2005},
    volumne = {24},
    number = {20},
    isitag = {ISI:000232671700002},
    abstract = {In many microarray studies the primary objective is to identify, from a
large panel of genes, those which are prognostic markers of a censored
survival endpoint such as time to disease recurrence or death. Often,
these genes are considered prognostic in that their respective
expressions are associated with the survival endpoint of interest. To
assess this association requires specifying an appropriate measure of
association a suitable test statistic and, as the number of genes is
large, proper handling of multiplicity issues. In this paper, we will
address these issues by utilizing a general correlation measure, a
non-parametric test statistic, and control of the family-wise error
rate by employing permutation resampling. Comprehensive simulation
studies are conducted to investigate the statistical properties of the
proposed procedure. The proposed method is applied to a recently
published data set on patients with lung cancer. Copyright (C) 2005
John Wiley & Sons, Ltd.},
    keywords = {Cox regression; FDR; FWER; rank correlation; single-step procedure},
    timescited = {0},
    pages = {3077--3088},
}
 
@article{Logan+Wang+Zhang:SiM:2005,
    author = {B. R. Logan and H. Wang and M. J. Zhang},
    title = {Pairwise multiple comparison adjustment in survival analysis},
    journal = {Statistics in Medicine},
    month = {AUG 30},
    year = {2005},
    volumne = {24},
    number = {16},
    isitag = {ISI:000231208300006},
    abstract = {Many clinical studies have as their endpoint the time until some event
(such as death) occurs. Often in such studies researchers are
interested in comparing several treatment or prognostic groups with one
another in terms of their survival curves. When many such pairwise
group comparisons are done, the chance of finding a false significance
among all of the comparisons is inflated above the usual desired
significance level. This paper investigates methods of adjusting the
survival analysis for the number of comparisons being made. These
methods are applied to a retrospective study conducted by the
International Bone Marrow Transplant Registry and compared in a
simulation study in terms of the power to detect actual differences in
the survival curves between the groups. Copyright (C) 2005 John Wiley &
Sons, Ltd.},
    keywords = {Bonferroni procedure; step-down procedure; closed test procedure;
log-rank test},
    timescited = {0},
    pages = {2509--2523},
}
 
@article{Thakkinstian+McElduff+D'Este:SiM:2005,
    author = {A. Thakkinstian and P. McElduff and C. D'Este and D. Duffy and J. Attia},
    title = {A method for meta-analysis of molecular association studies},
    journal = {Statistics in Medicine},
    month = {MAY 15},
    year = {2005},
    volumne = {24},
    number = {9},
    isitag = {ISI:000228735700001},
    abstract = {Although populationation-based molecular association Studies are
becoming increasingly popular, methodology for the meta-analysis of
these studies has been neglected, particularly with regard to two
issues: testing Hardy-Weinberg equilibrium (HWE), and pooling results
in a manner that reflects a biological model of gene effect. We propose
a process for pooling results from population-based molecular
association Studies which consists of the following steps: (1) checking
HWE using chi-square goodness of fit: we suggest performing sensitivity
analysis with and without Studies that are in HWE. (2) Heterogeneity is
then checked, and if present, possible causes are explored. (3) If no
heterogeneity is present, regression analysis is used to pool data and
to determine the gene effect. (4) If there is a significant gene
effect, pairwise group differences are analysed and these data are
allowed to 'dictate' the best genetic model. (5) Data may then be
pooled using this model. This method is easily performed using standard
software, and has the advantage of not assuming an a priori genetic
model. Copyright (c) 2004 John Wiley & Soils, Ltd.},
    keywords = {case-control studies; cohort studies; gene frequency; model
polymorphisin (genetics); regression},
    timescited = {6},
    pages = {1291--1306},
}
 
@article{Liao:SiM:2005,
    author = {J. J. Z. Liao},
    title = {Comparing the concentration curves directly in a pharmacokinetics, bioavailability/bioequivalence study},
    journal = {Statistics in Medicine},
    month = {MAR 30},
    year = {2005},
    volumne = {24},
    number = {6},
    isitag = {ISI:000227775300004},
    abstract = {In a traditional pharmacokinctics (PK), bioavailability
(BA)/bioequivalence (BE) study, the same number of time points and
sampling times are used for each subject. Often, an indirect inference
is then made on some PK parameters such as area under the plasma
concentration curve (AUC), maximum plasma concentration (C-max), time
to maximum plasma concentration (T-max) or half-life. However, since
these PK parameters are summarized from repeated measurements, a lot of
information can be lost. The indirect inferences on some PK parameters
are not always accurate. Taking the repeated measurements of the
concentration curve into consideration, a functional linear model has
been developed to compare concentration curves directly instead of the
PK parameters. Considering the nature of repeated measurements, a
multiple testing procedure is proposed to assess the equality of two
concentration curves. A real data set is used to demonstrate the
proposed procedure. Copyright (c) 2004 John Wiley I Sons, Ltd.},
    keywords = {concentration curve; functional linear model; sampling time; repeated
measurement; multiple testing},
    timescited = {0},
    pages = {883--891},
}
 
@article{Chi:SiM:2005,
    author = {Y. C. Chi},
    title = {Multiple testing procedures based on weighted {Kaplan-Meier} statistics for right-censored survival data},
    journal = {Statistics in Medicine},
    month = {JAN 15},
    year = {2005},
    volumne = {24},
    number = {1},
    isitag = {ISI:000226103000003},
    abstract = {In clinical trials or drug development studies, researchers are often
interested in identifying which treatments or dosages are more
effective than the standard one. Recently, several multiple testing
procedures based on weighted logrank tests have been proposed to
compare several treatments with a control in a one-way layout where
survival data are subject to random right-censorship. However, weighted
logrank tests are based on ranks, and these tests might not be
sensitive to the magnitude of the difference in survival times against
a specific alternative. Therefore, it is desirable to develop a more
robust and powerful multiple testing procedure. This paper proposes
multiple testing procedures based on two-sample weighted Kaplan-Meier
statistics, each comparing an individual treatment with the control, to
determine which treatments are more effective than the control. The
comparative results from a simulation study are presented and the
implementation of these methods to the prostate cancer clinical trial
and the renal carcinoma tumour study are presented. Copyright 2004 John
Wiley Sons, Ltd.},
    keywords = {multiple testing procedure; weighted Kaplan-Meier statistic;
right-censored data},
    timescited = {0},
    pages = {23--35},
}
 
@article{Cheung+Kwong+Chan:SiM:2004,
    author = {S. H. Cheung and K. S. Kwong and W. S. Chan and S. P. Leung},
    title = {Multiple comparisons with a control in families with both one-sided and two-sided hypotheses},
    journal = {Statistics in Medicine},
    month = {OCT 15},
    year = {2004},
    volumne = {23},
    number = {19},
    isitag = {ISI:000223817300003},
    abstract = {Comparing several treatments with a control is a common objective of
clinical studies. However, existing procedures mainly deal with
particular families of inferences in which all hypotheses are either
one- or two-sided. In this article, we seek to develop a procedure
which copes with a more general testing environment in which the family
of inferences is composed of a mixture of one- and two-sided
hypotheses. The proposed procedure provides a more flexible and
powerful tool than the existing method. The superiority of this method
is also substantiated by a simulation study of average power. Selected
critical values are tabulated for the implementation of the proposed
procedure. Finally, we provide an illustrative example with sample data
extracted from a medical experiment. Copyright (C) 2004 John Wiley
Sons, Ltd.},
    keywords = {Dunnett procedure; multiple comparisons with a control;
directional-mixed families; familywise type I error},
    timescited = {0},
    pages = {2975--2988},
}
 
@article{Edland+Slager+Farrer:SiM:2004,
    author = {S. D. Edland and S. Slager and M. Farrer},
    title = {Genetic association studies in {Alzheimer's} disease research: challenges and opportunities},
    journal = {Statistics in Medicine},
    month = {JAN 30},
    year = {2004},
    volumne = {23},
    number = {2},
    isitag = {ISI:000188117400002},
    abstract = {Genetic association studies have identified important risk factors for
Alzheimer's disease and other diseases. However, the ease with which
these methods can be applied and the shear number of polymorphisms in
the human genome has led to a well-characterized multiple comparison
problem-given the number of genetic variants being tested, it is likely
that many of the positive findings reported in the literature to date
will prove to be false positive findings explained simply by random
fluctuation in data and type I error. The disparity of findings in
initial positive reports versus subsequent negative replication studies
observed in the Alzheimer's disease literature underscores this
problem. The problem of a high false positive rate can be addressed in
part by using statistical correction for multiple comparisons in larger
and statistically more powerful samples and in meta-analyses of smaller
samples. National initiatives are now being considered to address this
problem by encouraging sharing of genetic material. Of equal concern in
planning future initiatives are methodological issues that are the
domain of the epidemiologist. In fact, it is possible that disparate
findings across case-control studies reported to date may be explained
in part by problems in the design, analysis and interpretation of these
studies. The involvement of epidemiologists may improve the situation
in this regard. For example, population stratification bias, control
selection bias and prevalent case bias can be minimized by careful
study design and by appropriate statistical analysis. Regarding
interpretation of case-control studies, a more careful consideration of
the strength of evidence for a given genetic variant may help to temper
enthusiasm for, or appropriately qualify, positive findings.
Epidemiologists have well-developed causal criteria for this purpose.
This paper reviews the current state of case-control studies of genetic
variants in Alzheimer's disease from the epidemiological perspective.
The problem of multiple comparisons and a high false positive rate is
reviewed. The potential for bias in case-control studies of Alzheimer's
disease is reviewed by way of example. Future initiatives to promote
case-control studies of genetic variants in Alzheimer's disease can
only benefit from increased awareness the tools of epidemiology.
Copyright (C) 2004 John Wiley Sons, Ltd.},
    keywords = {Alzheimer's disease; case-control study; type I error; multiple
comparisons; stratification bias; selection bias},
    timescited = {4},
    pages = {169--178},
}
 
@article{Bretz+Hothorn+Hsu:SiM:2003,
    author = {F. Bretz and L. A. Hothorn and J. C. Hsu},
    title = {Identifying effective and/or safe doses by stepwise confidence intervals for ratios},
    journal = {Statistics in Medicine},
    month = {MAR 30},
    year = {2003},
    volumne = {22},
    number = {6},
    isitag = {ISI:000181482200003},
    abstract = {Typical randomized clinical dose-finding studies consist of the
comparison of several doses of a drug versus a placebo. Interest lies
in estimating relevant doses among those under investigation for
efficacy and safety variables, such as the minimum effective dose or
the maximum safe dose (or estimating both doses simultaneously).
Step-down procedures have been proposed for comparing the standardized
differences of the dose groups against placebo. In this paper we
consider the ratio of population means and propose stepwise confidence
intervals for these ratios. These confidence intervals do not require
multiplicity adjustments and yield the same decisions as the associated
test procedures. In addition, several power concepts are investigated
within the present framework. The results allow sample size
determination in the design phase of a study for the probability of
estimating correctly the dose of interest. Auxiliary results of a
numerical study show the range of application of these methods.
Copyright (C) 2003 John Wiley Sons, Ltd.},
    keywords = {stepwise confidence intervals; ratios; therapeutic window; partitioning
principle; multiple testing},
    timescited = {8},
    pages = {847--858},
}
 
@article{Tangen+Koch:SiM:2001,
    author = {C. M. Tangen and G. G. Koch},
    title = {Non-parametric analysis of covariance for confirmatory randomized clinical trials to evaluate dose-response relationships},
    journal = {Statistics in Medicine},
    month = {SEP 15},
    year = {2001},
    volumne = {20},
    number = {17-18},
    isitag = {ISI:000170808800006},
    abstract = {In confirmatory randomized clinical trials that are designed to compare
multiple doses of a test treatment with a control group and with one
another, there are often statistical issues regarding compound
hypotheses and multiple comparisons which need to be considered. In
most cases the analysis plan needs a clear specification for the
proposed order for conducting statistical tests (or for managing the
overall significance level), which statistical methods will be used,
and whether adjustment for covariates will be performed. There are
several benefits of specifying non-parametric analysis of covariance
(ANCOVA) for performing the primary confirmatory analyses. Only minimal
assumptions are needed beyond randomization in the study design,
whereas regression model based methods have assumptions about model fit
for which departures may require modifications that are incompatible
with a fully prespecified analysis plan. Non-parametric methods provide
traditionally expected results of ANCOVA; namely, a typically small
adjustment to the estimate for a treatment comparison (so as to account
for random imbalance of covariates between treatment groups) and
variance reduction for this estimate when covariates are strongly
correlated with the response of interest. The application of
non-parametric ANCOVA is illustrated for two randomized clinical
trials. The first has a (3 x 4) factorial response surface design for
the comparison of 12 treatments (that is, combinations of three doses
of one drug and four doses of a second drug) for change in blood
pressure; and the second example addresses the comparison of three
doses of test treatment and placebo for time-to-disease progression.
This clinical trial has comparisons among treatments made for a
dichotomous criterion, Wilcoxon rank scores and averages of cumulative
survival rates. In each example, the non-parametric covariance method
provides variance reduction relative to its unadjusted counterpart.
Copyright (C) 2001 John Wiley & Sons, Ltd.},
    keywords = {NA},
    timescited = {2},
    pages = {2585--2607},
}
 
@article{Chen:SiM:2000,
    author = {Y. I. Chen},
    title = {Multiple comparisons in carcinogenesis study with right-censored survival data},
    journal = {Statistics in Medicine},
    month = {FEB 15},
    year = {2000},
    volumne = {19},
    number = {3},
    isitag = {ISI:000084997000006},
    abstract = {This paper considers the practical problem in animal carcinogenesis
experiments where several treatment groups are compared with a control
group in a one-way layout and the observed survival data are subject to
random right-censorship. Proposed herein are multiple testing
procedures based on two-sample weighted logrank statistics, each
comparing an individual treatment with the control, for determining
which treatments are more effective than the control. The associated
p-value of claiming a certain treatment is more effective than the
control is also discussed. A test-based confidence set for the scale
changes between each treatment and the control is then obtained. The
comparative results of a Monte Carlo error rate and power study for
small sample sizes are presented. Finally, a numerical example
involving renal carcinoma in mice demonstrates the feasibility of the
proposed multiple testing procedures and test-based confidence set.
Copyright (C) 2000 John Wiley & Sons, Ltd.},
    keywords = {NA},
    timescited = {2},
    pages = {353--367},
}
 
@article{Liu+Tsai+Wolf:SiM:1998,
    author = {P. Y. Liu and W. Y. Tsai and M. Wolf},
    title = {Design and analysis for survival data under order restrictions with a modified logrank test},
    journal = {Statistics in Medicine},
    month = {JUL 15},
    year = {1998},
    volumne = {17},
    number = {13},
    isitag = {ISI:000074678800004},
    abstract = {We previously proposed a class of ordered weighted logrank tests for
analysing censored survival data under order restrictions, However, the
power of these tests is asymmetrical with respect to possible
alternative configurations, While it is superior in most cases, the
power can be inferior to the non-ordered logrank test in extreme cases.
We propose a modified ordered logrank test which performs uniformly
better than the non-ordered test. The power of the modified test is
equivalent to the generalized Jonckheere's test but its computation is
much simpler, We give sample size requirements for sufficient power to
reject the global null hypothesis at specified hazard ratios between
the control group and the best group. Following Fisher's least
significant difference (LSD) strategy for multiple comparisons, power
investigations indicate that the nominal power for the global test
carries over to the control versus best comparison during pairwise
testing. The power for detecting intermediate survival differences is
inadequate but the sample sizes required to detect such differences may
be impractical in most applications, (C) 1998 John Wiley & Sons, Ltd.},
    keywords = {NA},
    timescited = {5},
    pages = {1469--1479},
}
 
@article{Shih+Quan:SiM:1997,
    author = {W. J. Shih and H. Quan},
    title = {Testing for treatment differences with dropouts present in clinical trials - {A} composite approach},
    journal = {Statistics in Medicine},
    month = {JUN 15},
    year = {1997},
    volumne = {16},
    number = {11},
    isitag = {ISI:A1997XD62300003},
    abstract = {A major problem in the analysis of clinical trials is missing data from
patients who drop out of the study before the predetermined schedule.
In this paper we consider the situation where the outcome measure is a
continuous variable and the final outcome at the end of the study is
the main interest. We argue that the hypothetical complete-data
marginal mean averaged over the dropout patterns is not as relevant
clinically as the conditional mean of the completers together with the
probability of completion or dropping out of the trial. We first take
the pattern-mixture modelling approach to factoring the likelihood
function, then direct the analysis to the multiple testings of a
composite of hypotheses that involves the probability of dropouts and
the conditional mean of the completers. We review three types of closed
step-down multiple-testing procedures for this application. Data from
several clinical trials are used to illustrate the proposed approach.
(C) 1997 by John Wiley & Sons, Ltd.},
    keywords = {NA},
    timescited = {30},
    pages = {1225--1239},
}
 
@article{Blair+Troendle+Beck:SiM:1996,
    author = {R. C. Blair and J. F. Troendle and R. W. Beck},
    title = {Control of familywise errors in multiple endpoint assessments via stepwise permutation tests},
    journal = {Statistics in Medicine},
    month = {JUN 15},
    year = {1996},
    volumne = {15},
    number = {11},
    isitag = {ISI:A1996UR76800003},
    abstract = {We describe permutation based sequentially rejective multiple
comparison procedures useful in multiple endpoint assessments. We used
Monte Carlo methods to compare the power of these newly devised tests
to that of tests due to Helm and Rom as well as to the classical
Bonferroni method. We illustrate applications of the methods with
analysis of visual field data collected from optic neuritis patients.
We conclude that the new methods are particularly useful when there are
many endpoints involved, the data are significantly correlated, and/or
the distributional assumptions are questionable.},
    keywords = {NA},
    timescited = {7},
    pages = {1107--1121},
}
 
@article{CHUANGSTEIN+TONG:SiM:1995,
    author = {C. CHUANGSTEIN and D. M. TONG},
    title = {MULTIPLE COMPARISONS PROCEDURES FOR COMPARING SEVERAL TREATMENTS WITH A CONTROL-BASED ON BINARY DATA},
    journal = {Statistics in Medicine},
    month = {DEC 15},
    year = {1995},
    volumne = {14},
    number = {23},
    isitag = {ISI:A1995TK13300001},
    abstract = {In this paper, we examine three approaches for comparing several
treatments with a control with use of binary response data. The first
approach relies on asymptotic theory applied to the Freeman-Tukey
transformation of the observed proportions. The second finds an
acceptance region based on the binomial distributions estimated under
the joint null hypotheses. The third approach applies Dunnett's
procedure to the binary data. We evaluated the actual overall type I
error rates of the Freeman-Tukey test and Dunnett's procedure using
both simulation and binomial calculations while we assessed those of
the binomial approach using simulation. Based on their capability to
preserve the desirable overall type I error rate, we provide
recommendations regarding the choices among the three approaches for
various occasions. In addition, we provide comments on the power of
these three procedures.},
    keywords = {NA},
    timescited = {6},
    pages = {2509--2522},
}
