
\documentclass[landscape]{slides}

%%\usepackage{Sweave}
\newenvironment{thebibliography}{}

\SweaveOpts{engine=R, eps=FALSE, keep.source = TRUE}
<<setup, echo = FALSE, results = hide>>=
set.seed(290875)
options(prompt = "R> ")
options(SweaveHooks = list(mai = function() par(mai = par("mai") * c(1, 2.4, 1, 1)),
                           mai3 = function() par(mai = par("mai") * c(1, 2, 1, 1))))
library("multcomp")
library("sandwich")
library("robustbase")
data("alpha", package = "coin")
data("bodyfat", package = "mboost")
data("alzheimer", package = "coin")
vcov.lmrob <- function(object) object$cov
@

\usepackage[coloremph,colorhighlight,LMU,printout]{RSlides}
\usepackage{url,listings}
\usepackage{SweaveSlides}
\usepackage{natbib}

\usepackage[utf8]{inputenc}

\usepackage{hyperref}

\input{header}
\usepackage{amstext}

\setkeys{Gin}{height = 0.9\textheight}

\title{Simultaneous Inference in \\ General Parametric Models}
\author{Torsten Hothorn \\ Institut fÃ¼r Statistik \\ 
(in collaboration with Frank Bretz, Novartis, and \\ Peter Westfall, Texas Tech)}
\fancyfoot[L]{\tiny 2008-04-25} %%\copyright{} 2007 Friedrich Leisch
\fancyfoot[R]{\arabic{page}}

\sloppy

\begin{document}

\maketitle

\newslide{Introduction}

\begin{center}
\includegraphics{figs/verbiss}
\includegraphics{figs/reh}
\includegraphics{figs/zaun}
\includegraphics[height=\textheight]{figs/rotbuche2007}
\includegraphics[height=\textheight]{figs/esche2007}

\end{center}

\newslide{Model}

$\M((\Z_1, \dots, \Z_n), \theta, \eta)$ is a (semiparametric) model with

\begin{itemize}
\item $n$ observations $(\Z_1, \dots, \Z_n)$
\item elemental parameters $\theta \in \R^p$ and
\item other (random or nuisance) parameters $\eta$.
\end{itemize}

We are interested in linear functions $\vartheta := \K \theta$ defined
by a constant matrix $\K \in \R^{k, p}$.

\newslide{Estimation}

$\hat{\theta}_n \in \R^p$ is an estimate of $\theta$ and
$\Sraw \in \R^{p,p}$ is an estimate of $\cov(\hat{\theta}_n)$ with
\begin{eqnarray*}
a_n \Sraw \cP \Sigmaraw \in \R^{p,p}
\end{eqnarray*}
for some positive, nondecreasing sequence $a_n$.

A multivariate central limit theorem is assumed:
\begin{eqnarray*}
a_n^{1/2} (\hat{\theta}_n - \theta) \cL \N_p(0, \Sigmaraw).
\end{eqnarray*}

We write $\hat{\theta}_n \an \N_p(\theta, \Sraw)$.

These assumptions are fulfilled for most of the models commonly in use.

\newslide{Distribution of $\vartheta$}

By Theorem 3.3.A in
Serfling (1980), the linear function $\hat{\vartheta}_n = \K 
\hat{\theta}_n$, i.e., an estimate of our parameters of interest,
also follows an approximate multivariate normal
distribution
\begin{eqnarray*}
\hat{\vartheta}_n = \K \hat{\theta}_n \an \N_k(\vartheta, \SK)
\end{eqnarray*}
with covariance matrix $\SK := \K \Sraw \K^\top$
for any fixed matrix $\K \in \R^{k,p}$

Therefore, we simply assume
\begin{eqnarray*}
\hat{\vartheta}_n \an \N_k(\vartheta, \SK) \text{ with }
a_n \SK \cP \SigmaK := \K \Sigma \K^\top \in \R^{k,k}
\end{eqnarray*}

\newslide{A Statistic and its Distribution}

Consider the multivariate statistic
\begin{eqnarray*}
\T_n := %% \frac{\hat{\vartheta}_n - \vartheta}{\sqrt{\diag(\SK)}} =
\D_n^{-1/2} (\hat{\vartheta}_n - \vartheta) 
%%\an \N_k(0, \Cor_n)
\end{eqnarray*}
where $\D_n = \diag(\SK)$ is the diagonal matrix given by the diagonal elements of
$\SK$.

By Slutzky's Theorem, this statistic is again asymptotically normally
distributed
\begin{eqnarray*}
\T_n \an \N_k(0, \Cor_n)
\end{eqnarray*}
where
\begin{eqnarray*}
\Cor_n = \D_n^{-1/2} \SK \D_n^{-1/2} \in \R^{k,k}
\end{eqnarray*}
is the correlation matrix of the $k$-dimensional statistic $\T_n$. 


\newslide{General Linear Hypothesis}

Consider the null hypothesis
\begin{eqnarray*}
H_0: \vartheta := \K \theta = \m.
\end{eqnarray*}

Classically, $F$- or $\chi^2$-statistics are used to test $H_0$.
However, a rejection of $H_0$ 
does not give further indication about the nature of the significant
result. Therefore, one is often interested in the individual null hypotheses
\begin{eqnarray*}
H_0^j: \vartheta_j = \m_j.
\end{eqnarray*}

Testing the hypotheses set $\{H_0^1, \ldots, H_0^k\}$ simultaneously thus requires the individual
assessments while maintaining the familywise error rate.

\newslide{A Maximum-Type Statistic}

An alternative test statistic for testing $H_0$ is
\begin{eqnarray*}
\max(|\T_n|)
\end{eqnarray*}

Can we approximate it's distribution under $H_0$ efficiently?

We have to find a good approximation of $\Prob(\max(|\T_n|) \le t)$
for some $t \in \R^+$.

\newslide{Null-Distribution and a Global Test}

\begin{eqnarray*}
\Prob(\max(|\T_n|) \le t) = \int\limits_{-t}^t \cdots \int\limits_{-t}^t
\varphi_k(x_1, \dots, x_k; \Cor) \, dx_1 \cdots dx_k =: g(\Cor, t) 
\end{eqnarray*}
where $\varphi_k$ is the $k$-dimensional normal density function.

$\Cor$ is not known but $g(\Cor, t)$ is a continuous function of $\Cor$ 
and converges as $\Cor_n \cP \Cor$. The integral can be approximated
by quasi-randomized Monte-Carlo methods (Genz, 1992, Genz and Bretz, 1999).

The resulting global $p$-value 
for $H_0$ is then 
\begin{eqnarray*}
p_\text{global} = 1 - g(\Cor_n, \max|\tt|)
\end{eqnarray*}
when $\T = \tt$ has been observed.

\newslide{Simultaneous Inference}

But what about the partial hypotheses $H_0^1, \ldots, H_0^k$?

It's simple!

The multiplicity adjusted $p$-value for the $j$th
individual two-sided hypothesis 
\begin{eqnarray*}
H_0^j: \vartheta_j = \m_j, j = 1, \dots, k,
\end{eqnarray*}
is given by 
\begin{eqnarray*}
p_j = 1 - g(\Cor_n, |t_j|),
\end{eqnarray*}
where $\tt = (t_1, \dots, t_k)$ denote the observed test statistics (single-step procedure).

Reject each $H_0^j$ at family-wise error rate $\alpha$ when $p_j \leq \alpha$.

\newslide{Simultaneous Confidence Intervals}

A simultaneous $(1 - 2\alpha)
\times 100\%$ confidence interval for $\vartheta$ is given by 
\begin{eqnarray*}
\hat{\vartheta}_n \pm q_\alpha \D_n^{1/2}
\end{eqnarray*}
where $q_\alpha$ is the (approximate) $1 - \alpha$ quantile of the distribution of $\max(|\T_n|)$.

\newslide{Examples: Linear Regression}

$\Z_i = (Y_i, \X_i), i = 1, \dots, n$, with response $Y_i$
and exploratory variables \\ $\X_i = (X_{i1}, \dots, X_{iq})$

Model:
\begin{eqnarray*}
Y_i = \beta_0 + \sum_{j = 1}^q \beta_j X_{ij} + \sigma \varepsilon_i,
\end{eqnarray*}
with elemental parameters $\theta = (\beta_0, \beta_1, \dots, \beta_q)$
estimated via
\begin{eqnarray*}
\hat{\theta}_n = \left(\X^\top\X\right)^{-1} \X^\top \Y \sim \N%
_{q+1}\left(\theta, \sigma^2 \left(\X^\top\X\right)^{-1}\right).
\end{eqnarray*}

Now
\begin{eqnarray*}
\hat{\vartheta}_n = \K \hat{\theta}_n \sim \N_k(\K \theta, \sigma^2 \K \left(\X^\top\X%
\right)^{-1} \K^\top)
\end{eqnarray*}
and
\begin{eqnarray*}
\T_n = \D_n^{-1/2} \hat{\vartheta}_n \sim t_{q+1}(n - q, \Cor) \quad \text{exact inference possible!}
\end{eqnarray*}

\newslide{Predicting Body Fat}

Garcia et al. (2005) describe a linear model
for total body fat prediction.

\textbf{Aim:} Based on $p = 9$ simple measurements (circumferences of elbow, knee etc)
we want to estimate a simple (!) formula to predict the total body fat obtained for
$n = 71$ healthy German women by means of Dual Energy X-Ray Absorptiometry. 

\textbf{Problem:} Variable selection!

\newslide{Linear Model Fit}

<<bodyfat-lm-fit, echo = TRUE, results = hide>>=
data("bodyfat", package = "mboost")
lmod <- lm(DEXfat ~ ., data = bodyfat)
summary(lmod)
@
<<bodyfat-lm-print, echo = FALSE>>=
printCoefmat(summary(lmod)$coefficients)
@


\newslide{Parameters of Interest}

<<bodyfat-lm-maxtest, echo = TRUE>>=
K <- cbind(0, diag(length(coef(lmod)) - 1))
rownames(K) <- names(coef(lmod))[-1]
lmod_glht <- glht(lmod, linfct = K) 
K
@

\newslide{$F$-Test}

<<bodyfat-lm-Ftest, echo = TRUE>>=
summary(lmod_glht, test = Ftest())
@

\newslide{Maximum Test}
<<bodyfat-lm-maxtest, echo = TRUE>>=
summary(lmod_glht)
@

\newslide{ANOVA}

Model:
\begin{eqnarray*}
Y_{ij} = \mu + \gamma_{j} + \varepsilon_{ij}
\end{eqnarray*}

Overparameterized, usually the elemental parameters are \\
$\theta = (\mu, \gamma_2 - \gamma_1, \gamma_3 - \gamma_1, \dots, \gamma_q - \gamma_1)$.

\textbf{Dunnett many-to-one comparisons}:
\begin{eqnarray*}
\K_\text{Dunnett} &=& (0, \diag(q)) \\
\vartheta_\text{Dunnett} &=& \K_\text{Dunnett} \theta = (\gamma_2 - \gamma_1, \gamma_3 - \gamma_1,
\dots, \gamma_q - \gamma_1)
\end{eqnarray*}

\textbf{Tukey all-pair comparisons}:
\begin{eqnarray*}
\K_\text{Tukey} &=& \left(
\begin{array}{rrr}
0 & 1 & 0 \\ 
0 & 0 & 1 \\ 
0 & 1 & -1%  
\end{array}  
\right) \\
\vartheta_\text{Tukey} &=& \K_\text{Tukey} \theta = (\gamma_2 - \gamma_1, \gamma_3 - \gamma_1,
\gamma_2 - \gamma_3)
\end{eqnarray*}

\newslide{Genetic Components of Alcoholism}

\begin{center}   
<<alpha-data-figure, echo = FALSE, fig = TRUE, width = 7, height = 5>>=
n <- table(alpha$alength)
op <- par()
par(cex.lab = 1.3, cex.axis = 1.3)
boxplot(elevel ~ alength, data = alpha, ylab = "Expression Level",
        xlab = "NACP-REP1 Allele Length", varwidth = TRUE)
axis(3, at = 1:3, labels = paste("n = ", n))
rankif <- function(data) trafo(data, numeric_trafo = rank)
@
\end{center}

\newpage

<<alpha-aov-tukey, echo = TRUE>>=
data("alpha", package = "coin")   
amod <- aov(elevel ~ alength, data = alpha)
library("multcomp")
confint(glht(amod, linfct = mcp(alength = "Tukey")))
@

\newpage

<<alpha-aov-tukey-sandwich, echo = TRUE>>=
amod_glht_sw <- glht(amod, linfct = mcp(alength = "Tukey"),
                      vcov = sandwich)
confint(amod_glht_sw)
@

\newpage

\setkeys{Gin}{height = 0.6\textheight}
\begin{center}
<<alpha-confint-plot, echo = FALSE, fig = TRUE, width = 8, height = 3.5>>=
par(mai = par("mai") * c(1, 2.1, 1, 0.5))
layout(matrix(1:2, ncol = 2))
ci1 <- confint(glht(amod, linfct = mcp(alength = "Tukey")))
ci2 <- confint(glht(amod, linfct = mcp(alength = "Tukey"), vcov = sandwich))
plot(ci1, xlim = c(-0.6, 2.6), main = expression(paste("Tukey (ordinary ", bold(S)[n], ")")),
    xlab = "Difference", ylim = c(0.5, 3.5))
plot(ci2, xlim = c(-0.6, 2.6), main = expression(paste("Tukey (sandwich ", bold(S)[n], ")")),
    xlab = "Difference", ylim = c(0.5, 3.5))
@
\end{center}  

\newslide{Generalized Mixed Models}

Model:
\begin{eqnarray*}
\E(\mathbf{y}_i) = h(\mathbf{X}_i \theta + \mathbf{Z} \mathbf{b}_i)
\end{eqnarray*}
for the $n_i$ observations in group $i$ with random effects $\mathbf{b}_i$.

We are interested in inference about $\K \theta$. 

For example in a logistic mixed model, in
confidence intervals for the predicted probabilities in $\hat{\vartheta}_n = \mathbf{X} \hat{\theta}_n$
\begin{eqnarray*}
\left(\left(1 + \exp\left(- \left(\hat{\vartheta}_n - q_\alpha \D_n^{1/2}\right)\right)\right)^{-1},
\left(1 + \exp\left(- \left(\hat{\vartheta}_n + q_\alpha \D_n^{1/2}\right)\right)\right)^{-1}\right).
\end{eqnarray*}

\newslide{Dear Browsing in Frankonia}

\setkeys{Gin}{height = 0.7\textheight}
\begin{center}
\includegraphics{figs/aischgrund}
\end{center}

<<trees-setup, echo = FALSE, results = hide>>=
library("multcomp")
library("lme4")
data("trees513", package = "multcomp")
trees513 <- subset(trees513, !species %in% c("fir", "softwood (other)"))
trees513$species <- trees513$species[,drop = TRUE]
@


<<trees-lmer, echo = TRUE>>=
mmod <- lmer(damage ~ species - 1 + (1 | lattice / plot),
              data = trees513, family = binomial())
K <- diag(length(fixef(mmod)))
@

<<trees-K-cosmetics, echo = FALSE, results = hide>>=
colnames(K) <- rownames(K) <- 
    paste(gsub("species", "", names(fixef(mmod))),
          " (", table(trees513$species), ")", sep = "")
@

<<trees-ci, echo = TRUE>>=
ci <- confint(glht(mmod, linfct = K))
ci$confint <- 1 - binomial()$linkinv(ci$confint)
ci$confint[,2:3] <- ci$confint[,3:2]
ci
@

\setkeys{Gin}{height = 0.9\textheight}

\begin{center}
<<trees-plot, echo = FALSE, mai = TRUE, fig = TRUE, width = 7, height = 4.5>>=
plot(ci, xlab = "Probability of Damage Caused by Browsing", xlim = c(0, 1), main = "",
     ylim = c(0.5, 6.5))
@
\end{center}

\newslide{References}

\small

Ada~L. Garcia, Karen Wagner, Torsten Hothorn, Corinna Koebnick, Hans-Joachim~F.
  Zunft, and Ulrike Trippo.
Improved prediction of body fat by measuring skinfold thickness,
  circumferences, and bone breadths.
\emph{Obesity Research}, 13\penalty0 (3):\penalty0 626--634, 2005.

Alan Genz.
Numerical computation of multivariate normal probabilities.
\emph{Journal of Computational and Graphical Statistics}, 1:\penalty0
  141--149, 1992.

Alan Genz and Frank Bretz.
Numerical computation of multivariate $t$-probabilities with
  application to power calculation of multiple contrasts.
\emph{Journal of Statistical Computation and Simulation},
  63:\penalty0 361--378, 1999.

Torsten Hothorn, Frank Bretz and Peter Westfall.
Simultaneous Inference in General Parametric Models.
\emph{Biometrical Journal}, 50\penalty0 (3), 2008.

Robert~J. Serfling.
\emph{Approximation Theorems of Mathematical Statistics}.
John Wiley \& Sons, New York, 1980.

\end{document}

